{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fa00c7b",
   "metadata": {},
   "source": [
    "Order of things to do:\n",
    "1. Import \n",
    "    - Round 1: Takes in the master cleaned list and opt-in list\n",
    "    - Rounds 2+: Takes in the master cleaned list, opt-in list, participants list, and full data list. \n",
    "    - Returns master and opt-in or errors (telling you what to fix)\n",
    "2. Dedup\n",
    "    - De-duplicates the opt-in and master lists. \n",
    "3. Sync\n",
    "    - Takes in master and opt-in lists.\n",
    "    - Returns participant list with new rows if necessary.\n",
    "4. Create data\n",
    "    - Produces or updates the full data list. \n",
    "5. Complete match  \n",
    "    - Completes the previous round if round > 1     \n",
    "6. Possible matches  \n",
    "7. Create match   \n",
    "8. Save data back to Google.\n",
    "9. Send emails.\n",
    "10. Send reminder emails.\n",
    "\n",
    "\n",
    "\n",
    "- Make sure that retrieved data doesn't become corrupted. \n",
    "- Make sure that the names of spreadsheets are passed along correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8075b941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "from matplotlib_inline import backend_inline\n",
    "backend_inline.set_matplotlib_formats('retina')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "#from openpyxl import load_workbook\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from ipywidgets import HBox, VBox\n",
    "from IPython.display import HTML\n",
    "import base64\n",
    "\n",
    "#import os\n",
    "from email.message import EmailMessage\n",
    "import ssl\n",
    "import smtplib\n",
    "\n",
    "import gspread\n",
    "#gc = gspread.oauth()\n",
    "gc = gspread.oauth(\n",
    "        credentials_filename='credentials.json',\n",
    "        authorized_user_filename='authorized_user.json',\n",
    "    )\n",
    "\n",
    "def copy(obj):\n",
    "    # true deep copy\n",
    "    return pickle.loads(pickle.dumps(obj))\n",
    "\n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx\n",
    "\n",
    "def convert_cell(cell):\n",
    "    # converts '[1, 2, 3, ...]' into [1, 2, 3, ...]\n",
    "    if cell != '[]':\n",
    "        a = cell.strip('][').split(', ')\n",
    "        b = [int(i) for i in a]\n",
    "        return b\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def init(df):\n",
    "    # reset some of the columns or create them if they don't exist \n",
    "    df['prior_matches'] = [ [] for _ in range(len(df)) ]\n",
    "    df['current_match'] = [ [] for _ in range(len(df)) ]\n",
    "    df['current_group'] = -1\n",
    "    df['num_prior_matches'] = 0\n",
    "    df['size_prev_match'] = 0 # whether were in a 3 or 4 group previously, or 0 if new\n",
    "    df['possible_matches'] = [ [] for _ in range(len(df)) ]\n",
    "    df['num_possible_matches'] = -1\n",
    "\n",
    "def create_download_link(df, title=\"Download CSV file\", filename=\"data.csv\"): \n",
    "    # turns the pandas DataFrame into a csv to download\n",
    "    csv = df.to_csv(index=True)\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n",
    "    html = html.format(payload=payload,title=title,filename=filename)\n",
    "    display(HTML(html))\n",
    "    \n",
    "\n",
    "def import_files():\n",
    "    # imports the round opt-ins and the previous round matching data\n",
    "    global spreadsheet, full_data, data, master, optin, number3groups, number4groups, participants_prev, participants, full_data_prev\n",
    "    \n",
    "    # import master sheet\n",
    "    spreadsheet = gc.open(spreadsheet_widget.value)\n",
    "    master_sheet = spreadsheet.worksheet('master_list')\n",
    "    master = np.array(master_sheet.get_all_values())\n",
    "    master = pd.DataFrame(data=master[1:,1:], index=master[1:,0].astype(int), columns=master[0,1:])\n",
    "    master['email'] = master['email'].str.lower()\n",
    "    master['email'] = master['email'].str.strip()\n",
    "    master['email_retype'] = master['email_retype'].str.lower()\n",
    "    master['email_retype'] = master['email_retype'].str.strip()\n",
    "    \n",
    "    # import opt-in\n",
    "    optin_sheet = spreadsheet.worksheet('optin' + str(round_widget.value))\n",
    "    optin = np.array(optin_sheet.get_all_values())\n",
    "    optin = pd.DataFrame(data=optin[1:,:], columns=['email', 'available', 'campus', 'degree'])\n",
    "    optin['email'] = optin['email'].str.lower()\n",
    "    optin['email'] = optin['email'].str.strip()\n",
    "    #optin['email_retype'] = optin['email_retype'].str.lower()\n",
    "    #optin['email_retype'] = optin['email_retype'].str.strip()\n",
    "    optin = copy(optin[optin['available'] == 'Yes'])\n",
    "    \n",
    "    \n",
    "    # import previous round data (if round > 1)\n",
    "    if round_widget.value > 1:\n",
    "        full_data_prev_sheet = spreadsheet.worksheet('full_data')\n",
    "        full_data_prev = np.array(full_data_prev_sheet.get_all_values())\n",
    "        full_data_prev = pd.DataFrame(data=full_data_prev[1:,1:], index=full_data_prev[1:,0].astype(int), columns=full_data_prev[0,1:])\n",
    "        \n",
    "        participants_prev_sheet = spreadsheet.worksheet('participants')\n",
    "        participants_prev = np.array(participants_prev_sheet.get_all_values())\n",
    "        participants_prev = pd.DataFrame(data=participants_prev[1:,1:], index=participants_prev[1:,0].astype(int), \\\n",
    "                                         columns=participants_prev[0,1:])\n",
    "        participants_prev['email'] = participants_prev['email'].str.lower()\n",
    "        participants_prev['email'] = participants_prev['email'].str.strip()\n",
    "    \n",
    "    print('Imported')\n",
    "\n",
    "def import_for_reminder():\n",
    "    # imports the data saved from the round in progress only for the purposes of sending a reminder email\n",
    "    global spreadsheet, full_data, data\n",
    "    spreadsheet = gc.open(spreadsheet_widget.value)\n",
    "    full_data_sheet = spreadsheet.worksheet('full_data')\n",
    "    full_data = np.array(full_data_sheet.get_all_values())\n",
    "    full_data = pd.DataFrame(data=full_data[1:,1:], index=full_data[1:,0].astype(int), columns=full_data[0,1:])\n",
    "    \n",
    "    full_data['prior_matches'] = \\\n",
    "        [convert_cell(row['prior_matches']) for index, row in full_data.iterrows()]\n",
    "    full_data['current_match'] = \\\n",
    "        [convert_cell(row['current_match']) for index, row in full_data.iterrows()]\n",
    "    full_data['possible_matches'] = \\\n",
    "        [convert_cell(row['possible_matches']) for index, row in full_data.iterrows()]\n",
    "    full_data['email'] = full_data['email'].str.lower()\n",
    "    full_data['email'] = full_data['email'].str.strip()\n",
    "    \n",
    "    data = copy(full_data[full_data['current_group']!='-1'])\n",
    "    data['current_group'] = data['current_group'].astype(int)\n",
    "    \n",
    "\n",
    "def dedup():\n",
    "    global master, optin\n",
    "    # check for email errors and duplicates in the master list and remove them \n",
    "    # check for email errors and duplicates in the opt-in list and remove them\n",
    "    \n",
    "    error_state = 0\n",
    "    print('checking emails match...')\n",
    "    # check emails for master\n",
    "    for index, row in master.iterrows():\n",
    "        if row['email'] != row['email_retype']:\n",
    "            print('Email disagreement for ID %s in Master list.' %str(index))\n",
    "            error_state += 1\n",
    "    \n",
    "    # tell you what to do \n",
    "    if error_state >= 1:\n",
    "        raise TypeError('Some emails don\\'t match. Fix and rerun')\n",
    "    if error_state == 0:\n",
    "        print('no email errors.')\n",
    "\n",
    "    # check duplicates for master\n",
    "    print('deduping...')\n",
    "    unique_emails, counts = np.unique(master['email'], return_counts=True)\n",
    "    if np.any(counts > 1):\n",
    "        print('Duplicates detected in Master list...fixing')\n",
    "        master.drop_duplicates(subset=['email'], keep='first', inplace=True, ignore_index=True)\n",
    "        #spreadsheet.worksheet('cleaned_master_list').update('A1', master.values.tolist())\n",
    "        print('Master duplicates removed')\n",
    "    else:\n",
    "        print('No duplicates deteted in Master list')\n",
    "    \n",
    "    # check duplicates for optin\n",
    "    unique_emails, counts = np.unique(optin['email'], return_counts=True)\n",
    "    # remove the first instance of multiple opt-ins, in case someone changed from Yes to No\n",
    "    if np.any(counts > 1):\n",
    "        print('Duplicates detected in Optin list...fixing')\n",
    "        optin.drop_duplicates(subset=['email'], keep='last', inplace=True, ignore_index=True)\n",
    "        print('Optin duplicates removed')\n",
    "    else:\n",
    "        print('No duplicates deteted in Optin list')\n",
    "    \n",
    "    # remove all the Nos\n",
    "    optin = optin[optin['available']=='Yes']\n",
    "    optin.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    print('Finished.')\n",
    "    \n",
    "def sync_lists():\n",
    "    '''\n",
    "    \n",
    "    JULY 25, 2024 : MAY NOT NEED ANYMORE. \n",
    "    \n",
    "    '''\n",
    "    # sync the opt-in list to the master list\n",
    "    global master, optin, participants\n",
    "    print('syncing the opt-in list to the master list...')\n",
    "    \n",
    "    # if round 1, generate the participants list from the master list\n",
    "    if round_widget.value == 1:\n",
    "        participants = copy(master)\n",
    "    # if rounds 2+, populate the participants list with recent additions to the master list\n",
    "    elif round_widget.value > 1:\n",
    "        participants = copy(pd.merge(master, participants_prev, how='left'))\n",
    "    \n",
    "    # check if the length of the intersection between the two lists is the same as the length of optin\n",
    "    # if it isn't, then that means there is an error\n",
    "    if np.count_nonzero(np.in1d(participants['email'].to_numpy(), optin['email'].to_numpy())) != len(optin):\n",
    "        if np.count_nonzero(np.in1d(participants['email'].to_numpy(), optin['email'].to_numpy())) < len(optin):\n",
    "            print('Lengths don\\'t match, likely an opt-in participant didn\\'t fill out the intake form')\n",
    "            print('Problematic email(s):',optin['email'][~np.in1d(optin['email'].to_numpy(), participants['email'].to_numpy())].to_numpy())\n",
    "            print('Either add an entry for these emails in the master list or delete them from the opt-in list. Then run again.')\n",
    "    \n",
    "        elif np.count_nonzero(np.in1d(participants['email'].to_numpy(), optin['email'].to_numpy())) > len(optin):\n",
    "            print('Lengths don\\'t match, likely there is a duplicate in the intake form')\n",
    "            print('This shouldn\\'t happen, so if it does, that\\'s not good. Stop and seek help.')\n",
    "    \n",
    "    else:\n",
    "        print('Lengths match, good, proceeding')\n",
    "        time.sleep(1)\n",
    "        # populate the current round opt-in column from the opt-in list\n",
    "        participants['optin'+str(round_widget.value)] = np.zeros(len(participants))\n",
    "        for i, answer in enumerate(np.in1d(participants['email'].to_numpy(), \\\n",
    "                                           optin['email'].to_numpy())):\n",
    "            if answer:\n",
    "                participants.loc[i, 'optin'+str(round_widget.value)] = 'Yes'\n",
    "            else:\n",
    "                participants.loc[i, 'optin'+str(round_widget.value)] = 'No'\n",
    "        \n",
    "        # replace field that's entirely space (or empty) with 'No'\n",
    "        participants.replace(r'^\\s*$', 'No', regex=True)\n",
    "                    \n",
    "        if np.any(participants['optin'+str(round_widget.value)] == 0):\n",
    "            # make sure they were each given 'Yes' or 'No'\n",
    "            print('ERROR')\n",
    "        else:\n",
    "            print('Lists synced')\n",
    "\n",
    "def complete_match(df):\n",
    "    # move the current match to the end of the list of prior matches and clear the columns \n",
    "    for index, row in df.iterrows():\n",
    "        df.loc[index, 'prior_matches'].extend(row['current_match'])\n",
    "        df.loc[index, 'num_prior_matches'] = len(row['prior_matches'])\n",
    "    df['size_prev_match'] = [len(a) for a in df['current_match'].tolist()]\n",
    "    df['current_match'] = [ [] for _ in range(len(df)) ]\n",
    "    df['current_group'] = -1\n",
    "\n",
    "def create_data():\n",
    "    global full_data, data, number3groups, number4groups, participants_round, participants\n",
    "    \n",
    "    if round_widget.value == 1:\n",
    "        # create the full_data list from scratch\n",
    "        full_data = copy(master)\n",
    "        if len(master) != len(participants):\n",
    "            print('ERROR: The lengths of the master list and participants list disagree. Fix and retry.')\n",
    "        data = copy(master[participants['optin'+str(round_widget.value)]=='Yes'])\n",
    "        init(full_data)\n",
    "        init(data)\n",
    "\n",
    "    if round_widget.value > 1:\n",
    "        # full_data_prev imported\n",
    "        # participants_prev imported and already converted to participants using the master list\n",
    "\n",
    "        # format the entries correctly\n",
    "        full_data_prev['prior_matches'] = \\\n",
    "            [convert_cell(row['prior_matches']) for index, row in full_data_prev.iterrows()]\n",
    "        full_data_prev['current_match'] = \\\n",
    "            [convert_cell(row['current_match']) for index, row in full_data_prev.iterrows()]\n",
    "        full_data_prev['possible_matches'] = \\\n",
    "            [convert_cell(row['possible_matches']) for index, row in full_data_prev.iterrows()]\n",
    "        full_data_prev['email'] = full_data_prev['email'].str.lower()\n",
    "        full_data_prev['email'] = full_data_prev['email'].str.strip()\n",
    "\n",
    "        # initialize empty rows in the data file for new participants\n",
    "        # this take a lot of lines\n",
    "        a = pd.merge(participants, full_data_prev, left_index=True, right_index=True, how='outer')\n",
    "        leftcols = [col for col in a.columns if '_x' in col] # lefthand side columns to keep \n",
    "        rightcols = a.columns[-7:] # righthand side columns to keep\n",
    "        a = a[np.append(leftcols, rightcols)]\n",
    "        a.columns = full_data_prev.columns\n",
    "        a['prior_matches'] = a['prior_matches'].apply(lambda d: d if isinstance(d, list) else [])\n",
    "        a['current_match'] = a['current_match'].apply(lambda d: d if isinstance(d, list) else [])\n",
    "        a['current_group'].fillna(-1, inplace=True)\n",
    "        a['num_prior_matches'].fillna(0, inplace=True)\n",
    "        a['size_prev_match'].fillna(0, inplace=True)\n",
    "        a['possible_matches'] = a['possible_matches'].apply(lambda d: d if isinstance(d, list) else [])\n",
    "        a['num_possible_matches'].fillna(-1, inplace=True)\n",
    "        full_data = copy(a)\n",
    "\n",
    "        # create data array for just the opt-ins\n",
    "        if len(full_data) != len(participants):\n",
    "            print('ERROR: length of `full_data` doesn\\'t equal length of `participants`.')\n",
    "        data = copy(full_data[participants['optin'+str(round_widget.value)]=='Yes'])\n",
    "\n",
    "    # calculate the number of groups of 3 and 4 we will have \n",
    "    n = len(data)\n",
    "    if groupsize_widget.value == 3:\n",
    "        # make groups of 3 and fill in the gaps with groups of 4\n",
    "        number3groups = n // 3\n",
    "        number4groups = n - (number3groups * 3)\n",
    "        number3groups = n // 3 - number4groups\n",
    "    elif groupsize_widget.value == 4:\n",
    "        # make groups of 4 and fill in the gaps with groups of 3\n",
    "        nn = n\n",
    "        number3groups = 0\n",
    "        while (nn / 4 - np.floor(nn / 4)) != 0:\n",
    "            nn -= 3 # keep subtracting groups of 3 until it's divisible by 4\n",
    "            number3groups += 1\n",
    "        number4groups = nn // 4\n",
    "\n",
    "    if round_widget.value > 1:\n",
    "        complete_match(data)\n",
    "        complete_match(full_data)\n",
    "        print('Previous round completed')\n",
    "    print('All data structures made')\n",
    "    \n",
    "def possible_matches(samedepartment=False):\n",
    "    # determines all the possible matches for each person in the program\n",
    "    # if samedepartment=False, DON'T allow 2 from same department\n",
    "    # if samedepartment=True, DO allow 2 from same department (for Virtual only right now)\n",
    "    data['possible_matches'] = [ [] for _ in range(len(data)) ]\n",
    "    data['num_possible_matches'] = -1\n",
    "    if samedepartment == False:\n",
    "        for index, row in data.iterrows():\n",
    "            non_previous_matches = data.index.to_numpy()[~np.in1d(data.index.to_numpy(), row['prior_matches'])]\n",
    "            non_same_department = data.index.to_numpy()[~(row['department'] == data['department'])]\n",
    "            data.loc[index, 'possible_matches'].extend(np.intersect1d(non_previous_matches, non_same_department))\n",
    "            data.loc[index, 'num_possible_matches'] = len(data.loc[index, 'possible_matches'])\n",
    "    if samedepartment == True:\n",
    "        for index, row in data.iterrows():\n",
    "            non_previous_matches = data.index.to_numpy()[~np.in1d(data.index.to_numpy(), row['prior_matches'])]\n",
    "            data.loc[index, 'possible_matches'].extend(non_previous_matches)\n",
    "            data.loc[index, 'num_possible_matches'] = len(data.loc[index, 'possible_matches'])\n",
    "\n",
    "\n",
    "def perform_random_loop(df):\n",
    "    # the loop that attempts to do the matching\n",
    "    out = 0 # variable to determine when we've succeeded\n",
    "    # clear any attemps to match that failed\n",
    "    df['current_match'] = [ [] for _ in range(len(df)) ]\n",
    "    df['current_group'] = -1\n",
    "    # create a random column \n",
    "    df.loc[:, 'randint'] = np.random.choice(np.arange(0, len(df)), size=len(df), replace=False)\n",
    "    \n",
    "    groupnum = 1 # a counter for the group number\n",
    "    # iterate through, starting with the most number of possible matches \n",
    "    for i, (index, row) in enumerate(df.sort_values(['size_prev_match', \\\n",
    "                                                     'num_possible_matches', \\\n",
    "                                                     'randint']).iterrows()):\n",
    "        # select possible matches for person1\n",
    "        if i == 0:\n",
    "            p1_possible = df.loc[index, 'possible_matches']\n",
    "        elif i > 0 :\n",
    "            if len(remaining) == 0:\n",
    "                out = 1\n",
    "                return out\n",
    "                break\n",
    "            elif index not in remaining.index.tolist(): \n",
    "                continue\n",
    "            else:\n",
    "                p1_possible = np.intersect1d(remaining.loc[index, 'possible_matches'], \\\n",
    "                                             remaining.index.tolist())\n",
    "        if len(p1_possible) <= 1:\n",
    "            return out\n",
    "            break\n",
    "        # pick a random person2\n",
    "        p2 = df.loc[p1_possible].sample(1)\n",
    "        p2_possible = p2['possible_matches'].tolist()\n",
    "        # take person1 possible matches and remove person2 and all of person2's not possible matches\n",
    "        p1p2_possible_step1 = np.array(p1_possible)[~np.isin(p1_possible, p2.index.tolist())] # remove p2\n",
    "        p1p2_possible = p1p2_possible_step1[np.isin(p1p2_possible_step1, p2_possible)]\n",
    "\n",
    "        if len(p1p2_possible) == 0:\n",
    "            return out\n",
    "            break\n",
    "        # pick a random person3\n",
    "        p3 = df.loc[p1p2_possible].sample(1)\n",
    "        p3_possible = p3['possible_matches'].tolist()\n",
    "\n",
    "        if groupnum <= number4groups:\n",
    "            # take person3 out oc p1p2_possible\n",
    "            p1p2p3_possible_step1 = np.array(p1p2_possible)[~np.isin(p1p2_possible, p3.index.tolist())] \n",
    "            # keep only person3's possible matches \n",
    "            p1p2p3_possible = p1p2p3_possible_step1[np.isin(p1p2p3_possible_step1, p3_possible)]\n",
    "            \n",
    "            if len(p1p2p3_possible) == 0:\n",
    "                return out\n",
    "                break\n",
    "            # pick a random person4\n",
    "            p4 = df.loc[p1p2p3_possible].sample(1)\n",
    "\n",
    "            # write the current match for all *4* group members\n",
    "            df.loc[index, 'current_match'].extend([index, p2.index[0], p3.index[0], p4.index[0]])\n",
    "            df.loc[p2.index[0], 'current_match'].extend([p2.index[0], index, p3.index[0], p4.index[0]])\n",
    "            df.loc[p3.index[0], 'current_match'].extend([p3.index[0], index, p2.index[0], p4.index[0]])\n",
    "            df.loc[p4.index[0], 'current_match'].extend([p4.index[0], index, p2.index[0], p3.index[0]])\n",
    "            \n",
    "            df.loc[index, 'current_group'] = groupnum\n",
    "            df.loc[p2.index[0], 'current_group'] = groupnum\n",
    "            df.loc[p3.index[0], 'current_group'] = groupnum\n",
    "            df.loc[p4.index[0], 'current_group'] = groupnum\n",
    "            \n",
    "        else:\n",
    "            # write the current match for all *3* group members\n",
    "            df.loc[index, 'current_match'].extend([index, p2.index[0], p3.index[0]])\n",
    "            df.loc[p2.index[0], 'current_match'].extend([p2.index[0], index, p3.index[0]])\n",
    "            df.loc[p3.index[0], 'current_match'].extend([p3.index[0], index, p2.index[0]])\n",
    "            \n",
    "            df.loc[index, 'current_group'] = groupnum\n",
    "            df.loc[p2.index[0], 'current_group'] = groupnum\n",
    "            df.loc[p3.index[0], 'current_group'] = groupnum\n",
    "\n",
    "        # create a new version of the overall df with the matches rows removed\n",
    "        if i == 0:\n",
    "            if groupnum <= number4groups:\n",
    "                remaining = df.loc[df.index.difference((index, p2.index[0], p3.index[0], p4.index[0]))]\n",
    "            else:\n",
    "                remaining = df.loc[df.index.difference((index, p2.index[0], p3.index[0]))]\n",
    "        if i > 0:\n",
    "            if groupnum <= number4groups:\n",
    "                remaining = remaining.loc[remaining.index.difference((index, p2.index[0], \\\n",
    "                                                                      p3.index[0], p4.index[0]))]\n",
    "            else:\n",
    "                remaining = remaining.loc[remaining.index.difference((index, p2.index[0], p3.index[0]))]\n",
    "\n",
    "        if i == len(df) - 1:\n",
    "            out = 1\n",
    "            return out\n",
    "\n",
    "        groupnum+=1\n",
    "\n",
    "def create_match():\n",
    "    # calls the matching loop up to 1000 times to create the match \n",
    "    global out, full_data, data, participants, participants_round\n",
    "    counter = 0\n",
    "    out = 0\n",
    "    while out == 0:\n",
    "        counter += 1\n",
    "        out = perform_random_loop(data)  \n",
    "        print(counter, '\\r', end='')\n",
    "        if counter >= 1000:\n",
    "            print('match failed, not possible')\n",
    "            break\n",
    "    if out == 1:\n",
    "        print('match created')\n",
    "    if ((out == 0) and (checkbox_widget.value)):\n",
    "        print('Allowing up to 2 law students in the same group...')\n",
    "        # divide the law students into 2 random groups\n",
    "        half_law = len(data[data['department'] == 'School of Law'])//2\n",
    "        data.loc[data[data['department'] == 'School of Law'].sample(half_law).index, 'department'] = 'School of Law 1'\n",
    "        data.loc[data[data['department'] == 'School of Law'].index, 'department'] = 'School of Law 2'\n",
    "        # have to re-run the possible matches determination\n",
    "        possible_matches()\n",
    "        # then continue as normal\n",
    "        counter = 0\n",
    "        while out == 0:\n",
    "            counter += 1\n",
    "            out = perform_random_loop(data)\n",
    "            print(counter, '\\r', end='')\n",
    "            if counter >= 1000:\n",
    "                print('match failed again, really not possible')\n",
    "                break\n",
    "        if out == 1:\n",
    "            print('match created with double law students')\n",
    "            #print(len(data[(data['current_group'].to_numpy() == -1) & (data['school'].to_numpy() == 'School of Law')]))\n",
    "            counter += 1\n",
    "            \n",
    "    # use data to populate participants_round, full_data, and participants\n",
    "    participants_round = copy(participants[participants['optin' + str(round_widget.value)]=='Yes'])\n",
    "    participants_round['group' + str(round_widget.value)] = data['current_group']\n",
    "    participants = pd.merge(participants, participants_round, how='left')\n",
    "    full_data.loc[data.index, :] = copy(data)   \n",
    "\n",
    "def save_data():\n",
    "    if out == 0:\n",
    "        print('match failed, no data saved')\n",
    "    else:\n",
    "        global full_data_to_save, participants_to_save\n",
    "        # create data in a format that can be saved to Google\n",
    "        # add headers and index to the data\n",
    "\n",
    "        full_data_to_save = copy(full_data.astype('str').values.tolist())\n",
    "        full_data_index = full_data.index.tolist()\n",
    "        for i, idx_value in enumerate(full_data_index):\n",
    "            full_data_to_save[i].insert(0, idx_value)\n",
    "        full_data_to_save.insert(0, ['UNIQUE_ID'] + full_data.columns.values.tolist())\n",
    "\n",
    "        participants_to_save = copy(participants.astype('str').values.tolist())\n",
    "        participants_index = participants.index.tolist()\n",
    "        for i, idx_value in enumerate(participants_index):\n",
    "            participants_to_save[i].insert(0, idx_value)\n",
    "        participants_to_save.insert(0, ['UNIQUE_ID'] + participants.columns.values.tolist())\n",
    "\n",
    "\n",
    "        try:\n",
    "            spreadsheet.add_worksheet('full_data', rows=len(full_data)+2, cols=len(full_data.columns)+2)\n",
    "        except:\n",
    "            pass\n",
    "        spreadsheet.worksheet('full_data').clear()\n",
    "        spreadsheet.worksheet('full_data').update('A1', full_data_to_save)\n",
    "\n",
    "\n",
    "        try:\n",
    "            spreadsheet.add_worksheet('participants', rows=len(participants)+2, cols=len(participants.columns)+2)\n",
    "        except:\n",
    "            pass\n",
    "        spreadsheet.worksheet('participants').clear()\n",
    "        spreadsheet.worksheet('participants').update('A1', participants_to_save)\n",
    "\n",
    "        print('spreadsheets updated')\n",
    "\n",
    "def send_emails():\n",
    "    if out == 0:\n",
    "        print('match failed, no emails sent')\n",
    "    else:\n",
    "        global spreadsheet, full_data, data, number3groups, number4groups, participants_round, participants\n",
    "        print('sending emails...')\n",
    "        for group_num in np.arange(1, data['current_group'].max()+1):\n",
    "            print(group_num, '\\r', end='')\n",
    "            time.sleep(2)\n",
    "            group = data.loc[data['current_group'] == group_num]\n",
    "\n",
    "            email_sender = 'bumeetup@bu.edu'\n",
    "            email_password = password_widget.value\n",
    "\n",
    "            email_recipients = group['email'].tolist()\n",
    "            greeting = ', ' . join(group['first_name'].tolist()[:-1] + \\\n",
    "                                   ['and ' + group['first_name'].tolist()[-1]])\n",
    "\n",
    "            # import the email from the spreadsheet and fix the formatting\n",
    "            email_sheet = spreadsheet.worksheet('match_email')\n",
    "            email = ''\n",
    "            for l in email_sheet.get_all_values():\n",
    "                if l[0] == '':\n",
    "                    email += '\\n\\n'\n",
    "                elif 'XXX' in l[0]:\n",
    "                    email += l[0].replace('XXX', '%s')\n",
    "                else:\n",
    "                    email += l[0]\n",
    "\n",
    "            subject = 'BU Meetup Round %s'%str(round_widget.value)\n",
    "            body = email%(greeting, round_widget.value)\n",
    "\n",
    "            em = EmailMessage()\n",
    "            em['From'] = email_sender\n",
    "            em['To'] = email_recipients\n",
    "            em['Subject'] = subject\n",
    "            em.set_content(body)\n",
    "\n",
    "            context = ssl.create_default_context()\n",
    "\n",
    "            with smtplib.SMTP_SSL('smtp.gmail.com', 465, context=context) as smtp:\n",
    "                smtp.login(email_sender, email_password)\n",
    "                smtp.sendmail(email_sender, email_recipients, em.as_string())\n",
    "\n",
    "        print('emails sent       ', '\\r', end='')\n",
    "\n",
    "def send_reminder_emails():\n",
    "    global spreadsheet, full_data, data, number3groups, number4groups, participants_round, participants\n",
    "    print('sending reminder emails...')\n",
    "    for group_num in np.arange(1, data['current_group'].max()+1):\n",
    "        print(group_num, '\\r', end='')\n",
    "        time.sleep(2)\n",
    "        group = data.loc[data['current_group'] == group_num]\n",
    "\n",
    "        email_sender = 'bumeetup@bu.edu'\n",
    "        email_password = password_widget.value\n",
    "\n",
    "        email_recipients = group['email'].tolist()\n",
    "        greeting = ', ' . join(group['first_name'].tolist()[:-1] + \\\n",
    "                               ['and ' + group['first_name'].tolist()[-1]])\n",
    "        \n",
    "        # import the email from the spreadsheet and fix the formatting\n",
    "        email_sheet = spreadsheet.worksheet('reminder_email')\n",
    "        email = ''\n",
    "        for l in email_sheet.get_all_values():\n",
    "            if l[0] == '':\n",
    "                email += '\\n\\n'\n",
    "            elif 'XXX' in l[0]:\n",
    "                email += l[0].replace('XXX', '%s')\n",
    "            else:\n",
    "                email += l[0]\n",
    "        \n",
    "        subject = 'Reminder: BU Meetup Round %s'%str(round_widget.value)\n",
    "        body = email%(greeting, round_widget.value)\n",
    "        \n",
    "        em = EmailMessage()\n",
    "        em['From'] = email_sender\n",
    "        em['To'] = email_recipients\n",
    "        em['Subject'] = subject\n",
    "        em.set_content(body)\n",
    "\n",
    "        context = ssl.create_default_context()\n",
    "\n",
    "        with smtplib.SMTP_SSL('smtp.gmail.com', 465, context=context) as smtp:\n",
    "            smtp.login(email_sender, email_password)\n",
    "            smtp.sendmail(email_sender, email_recipients, em.as_string())\n",
    "\n",
    "    print('reminder emails sent       ', '\\r', end='')\n",
    "\n",
    "    \n",
    "# initialize jupyter widgets \n",
    "style = {'description_width': 'initial'}\n",
    "layout = widgets.Layout(width='auto', height='35px')\n",
    "\n",
    "spreadsheet_widget = widgets.Text(\n",
    "    description='Spreadsheet name:', \n",
    "    disabled=False, \n",
    "    style=style)\n",
    "\n",
    "round_widget = widgets.Dropdown(\n",
    "    options=np.arange(1, 10),\n",
    "    description='Matching round:', \n",
    "    disabled=False, \n",
    "    style=style)\n",
    "\n",
    "groupsize_widget = widgets.Dropdown(\n",
    "    options=[4,3],\n",
    "    description='Group Size',\n",
    "    disabled=False,\n",
    "    style=style)\n",
    "\n",
    "password_widget = widgets.Text(\n",
    "    description='Email password:', \n",
    "    disabled=False, \n",
    "    style=style)\n",
    "\n",
    "checkbox_widget = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Allow 2 law students in a group if necessary',\n",
    "    disabled=False, \n",
    "    style=style)\n",
    "\n",
    "match_button = widgets.Button(description='Run Match, Notify Groups, Update Data', layout=layout, display='flex', \\\n",
    "                              flex_flow='column', align_items='stretch')\n",
    "remind_button = widgets.Button(description='Remind Groups', layout=layout, display='flex', \\\n",
    "                               flex_flow='column', align_items='stretch')\n",
    "\n",
    "def display_widget():\n",
    "    display(round_widget), \\\n",
    "    display(spreadsheet_widget), \\\n",
    "    display(groupsize_widget),\\\n",
    "    display(password_widget), \\\n",
    "    display(checkbox_widget), \\\n",
    "    display(match_button)\n",
    "    display(remind_button)\n",
    "\n",
    "# functions for each widget button press\n",
    "    \n",
    "def event_match(button):\n",
    "    # do everything\n",
    "    clear_output()\n",
    "    display_widget()\n",
    "    time.sleep(1)\n",
    "    import_files()\n",
    "    time.sleep(1)\n",
    "    dedup()\n",
    "    time.sleep(1)\n",
    "    sync_lists()\n",
    "    time.sleep(1)\n",
    "    create_data()\n",
    "    time.sleep(1)\n",
    "    possible_matches()\n",
    "    time.sleep(1)\n",
    "    create_match()\n",
    "    time.sleep(1)\n",
    "    save_data()\n",
    "    time.sleep(1)\n",
    "    send_emails() \n",
    "    \n",
    "def event_remind(button):\n",
    "    clear_output()\n",
    "    display_widget()\n",
    "    time.sleep(1)\n",
    "    import_for_reminder()\n",
    "    time.sleep(1)\n",
    "    send_reminder_emails() \n",
    "    \n",
    "    \n",
    "# connecting the jupyter buttons to the actions for each button \n",
    "match_button.on_click(event_match)\n",
    "remind_button.on_click(event_remind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286db0e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1e77fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# working on the file organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "e5ae0340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# values for testing\n",
    "master_file = \"Intake_Fall23_noemails\"\n",
    "roundvalue = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "da8c8851",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_files():\n",
    "    # imports the round opt-ins and the previous round matching data\n",
    "    global master, intake, condensed, full_data, data, optin, number3groups, number4groups, participants_prev, participants, full_data_prev\n",
    "    \n",
    "    # import intake sheet from master file\n",
    "    master = gc.open(master_file)\n",
    "    intake = master.worksheet('intake_list')\n",
    "    intake = np.array(intake.get_all_values())\n",
    "    intake = pd.DataFrame(data=intake[1:,:], columns=intake[0,:])\n",
    "    email_cols = [_ for _ in intake.columns if 'email' in _]\n",
    "    intake[email_cols[0]] = intake[email_cols[0]].str.lower()\n",
    "    intake[email_cols[0]] = intake[email_cols[0]].str.strip()\n",
    "    intake[email_cols[1]] = intake[email_cols[1]].str.lower()\n",
    "    intake[email_cols[1]] = intake[email_cols[1]].str.strip()\n",
    "    # assign new unique ids to new participants\n",
    "    need_new_unique_ids = np.arange(intake[intake['User ID'] != ''].index[-1]+1, len(intake))\n",
    "    intake['User ID'] = intake.loc[intake['User ID'] != '', 'User ID'].astype(int).tolist() + [int(intake.loc[need_new_unique_ids[0]-1, 'User ID'])+i+1 for i, index in enumerate(need_new_unique_ids)]\n",
    "\n",
    "    #########-------------------### NEED TO DEDUP THE INTAKE LIST HERE\n",
    "\n",
    "    # create or update the condensed_responses sheet\n",
    "    condensed = copy(intake.iloc[:, np.arange(0, 10)])\n",
    "    condensed.columns = ['User_ID', 'Timestamp', 'full_name', 'first_name', 'pronouns', 'email', 'email_retype', 'campus', 'degree', 'school']\n",
    "    condensed_department_columns = intake.iloc[:, np.arange(10, len(intake.columns))]\n",
    "    condensed_department_column = []\n",
    "    for index, row in condensed_department_columns.iterrows():\n",
    "        for i, item in enumerate(row):\n",
    "            if item != '':\n",
    "                condensed_department_column.append(item)\n",
    "                break\n",
    "            if i+1 == len(row):\n",
    "                condensed_department_column.append(condensed.loc[index, 'school'])\n",
    "    condensed['department'] = condensed_department_column\n",
    "\n",
    "    # import opt-in sheet\n",
    "    #optin_sheet = master.worksheet('optin' + str(round_widget.value))\n",
    "    optin_sheet = master.worksheet('optin' + str(roundvalue))\n",
    "    optin = np.array(optin_sheet.get_all_values())\n",
    "    optin = pd.DataFrame(data=optin[1:,:], columns=['email', 'available'])\n",
    "    optin = copy(optin[optin['available'] == 'Yes'])\n",
    "    optin['email'] = optin['email'].str.lower()\n",
    "    optin['email'] = optin['email'].str.strip()\n",
    "\n",
    "    # remove duplicates in the optin\n",
    "    optin = optin.drop_duplicates(subset='email', keep='last') # keep the last in case someone changed \n",
    "\n",
    "    # merge the optin into condensed \n",
    "    condensed = pd.merge(condensed, optin[['email', 'available']], on='email', how='left')\n",
    "    condensed['available'] = condensed['available'].fillna('No')\n",
    "    condensed.rename(columns={'available': 'optin' + str(roundvalue)}, inplace=True)\n",
    "    #condensed.rename(columns={'available': 'optin' + str(round_widget.value)}, inplace=True)\n",
    "    \n",
    "    #if round_widget.value > 1:\n",
    "    if roundvalue > 1:\n",
    "        all_data_prev_sheet = master.worksheet('all_data')\n",
    "        all_data_prev = np.array(all_data_prev_sheet.get_all_values())\n",
    "        all_data_prev = pd.DataFrame(data=all_data_prev[1:,:], columns=all_data_prev[0,:])\n",
    "        \n",
    "        all_participants_prev_sheet = master.worksheet('all_participants')\n",
    "        all_participants_prev = np.array(all_participants_prev_sheet.get_all_values())\n",
    "        all_participants_prev = pd.DataFrame(data=all_participants_prev[1:,:], columns=all_participants_prev[0,:])\n",
    "        all_participants_prev['User_ID'] = [int(row['User_ID']) for index, row in all_participants_prev.iterrows()]\n",
    "        \n",
    "        all_participants_prev_mini = pd.concat([all_participants_prev[['User_ID']], all_participants_prev.iloc[:, 11:]], axis=1)\n",
    "        all_participants = pd.merge(condensed, all_participants_prev_mini, on=['User_ID'], how='left')\n",
    "        all_participants.insert(len(all_participants.columns)-1, 'optin' + str(round_widget.value), all_participants.pop('optin' + str(round_widget.value)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "28116735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import_files()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "45f49a27",
   "metadata": {},
   "source": [
    "data = copy(full_data[(participants['optin'+str(round_widget.value)]=='Yes').to_numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "0d878680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(program):\n",
    "    # program must be one of the following: 'Doctoral', 'Masters', 'Med', 'Virtual'\n",
    "    global all_data, all_participants, all_data_prev, all_participants_prev, full_data, data, number3groups, number4groups, participants_round, participants\n",
    "    \n",
    "    #if round_widget.value == 1:\n",
    "    if roundvalue == 1:\n",
    "        # create the full_data list from scratch\n",
    "        if program == 'Doctoral':\n",
    "            participants = copy(condensed[np.logical_and((condensed['campus']=='Charles River Campus').to_numpy(), condensed['degree'].str.contains('Doctoral').to_numpy())])\n",
    "            full_data = copy(participants)\n",
    "        elif program == 'Masters':\n",
    "            participants = copy(condensed[np.logical_and((condensed['campus']=='Charles River Campus').tolist(), condensed['degree'].str.contains('Masters').tolist())])\n",
    "            full_data = copy(participants)\n",
    "        elif program == 'Med':\n",
    "            participants = copy(condensed[(condensed['campus']=='BU Medical Campus').tolist()])\n",
    "            full_data = copy(participants)\n",
    "        elif program == 'Virtual':\n",
    "            participants = copy(condensed[(condensed['campus']=='Virtual').tolist()])\n",
    "            full_data = copy(participants)\n",
    "        full_data.drop(columns='optin1', inplace=True)\n",
    "        data = copy(full_data[(participants['optin'+str(round_widget.value)]=='Yes').to_numpy()])\n",
    "        init(full_data)\n",
    "        init(data)\n",
    "\n",
    "    #if round_widget.value > 1:\n",
    "    if roundvalue > 1:\n",
    "        #if program == 'Doctoral':\n",
    "        #    full_data_prev = copy(participants)\n",
    "        \n",
    "        # full_data_prev imported\n",
    "        # participants_prev imported and already converted to participants using the master list <---- THIS DOESN'T SEEM RIGHT\n",
    "        \n",
    "        '''\n",
    "        # format the entries correctly\n",
    "        all_data_prev['prior_matches'] = \\\n",
    "            [convert_cell(row['prior_matches']) for index, row in all_data_prev.iterrows()]\n",
    "        all_data_prev['current_match'] = \\\n",
    "            [convert_cell(row['current_match']) for index, row in all_data_prev.iterrows()]\n",
    "        all_data_prev['possible_matches'] = \\\n",
    "            [convert_cell(row['possible_matches']) for index, row in all_data_prev.iterrows()]\n",
    "        all_data_prev['email'] = all_data_prev['email'].str.lower()\n",
    "        all_data_prev['email'] = all_data_prev['email'].str.strip()\n",
    "        '''\n",
    "\n",
    "        # initialize empty rows in the data file for new participants\n",
    "        # this take a lot of lines\n",
    "        a = pd.merge(all_participants, all_data_prev, left_index=True, right_index=True, how='outer')\n",
    "        leftcols = [col for col in a.columns if '_x' in col] # lefthand side columns to keep \n",
    "        rightcols = a.columns[-7:] # righthand side columns to keep\n",
    "        a = a[np.append(leftcols, rightcols)]\n",
    "        a.columns = all_data_prev.columns\n",
    "        a['prior_matches'] = a['prior_matches'].apply(lambda d: d if isinstance(d, list) else [])\n",
    "        a['current_match'] = a['current_match'].apply(lambda d: d if isinstance(d, list) else [])\n",
    "        a['current_group'] = a['current_group'].fillna(-1)\n",
    "        a['num_prior_matches'] = a['num_prior_matches'].fillna(0)\n",
    "        a['size_prev_match'] = a['size_prev_match'].fillna(0)\n",
    "        a['possible_matches'] = a['possible_matches'].apply(lambda d: d if isinstance(d, list) else [])\n",
    "        a['num_possible_matches'] = a['num_possible_matches'].fillna(-1)\n",
    "        all_data = copy(a)\n",
    "\n",
    "        # create data array for just the opt-ins\n",
    "        #if len(all_data) != len(participants):\n",
    "        #    print('ERROR: length of `all_data` doesn\\'t equal length of `participants`.')\n",
    "        #data = copy(all_data[participants['optin'+str(round_widget.value)]=='Yes'])\n",
    "        \n",
    "        complete_match(all_data)\n",
    "        # _prev is from the end of the previous match (without new signups added)\n",
    "        all_data_prev = copy(all_data)\n",
    "        # add in the new signups that we already have in the condensed list\n",
    "        all_data = pd.merge(condensed.loc[:, condensed.columns[:-1]], all_data, how='left')\n",
    "        \n",
    "        # prep the new columns as needed\n",
    "        prior_match_col = np.where(all_data.columns == 'prior_matches')[0][0]\n",
    "        current_match_col = np.where(all_data.columns == 'current_match')[0][0]\n",
    "        possible_match_col = np.where(all_data.columns == 'possible_matches')[0][0]\n",
    "        current_group_col = np.where(all_data.columns == 'current_group')[0][0]\n",
    "        num_possible_matches_col = np.where(all_data.columns == 'num_possible_matches')[0][0]\n",
    "        num_prior_matches_col = np.where(all_data.columns == 'num_prior_matches')[0][0]\n",
    "        size_prev_match_col = np.where(all_data.columns == 'size_prev_match')[0][0]\n",
    "        \n",
    "        def replace_na(value, replacer):\n",
    "            if value == []:\n",
    "                return value\n",
    "            try:\n",
    "                if pd.isna(value):\n",
    "                    return replacer\n",
    "                return value\n",
    "            except ValueError as e:\n",
    "                return value\n",
    "    \n",
    "        cols_with_lists = [prior_match_col, current_match_col, possible_match_col]\n",
    "        cols_with_negones = [current_group_col, num_possible_matches_col]\n",
    "        cols_with_zeros = [num_prior_matches_col, size_prev_match_col]\n",
    "        all_data.iloc[:, cols_with_lists] = all_data.iloc[:, cols_with_lists].map(replace_na, replacer=[])\n",
    "        all_data.iloc[:, cols_with_negones] = all_data.iloc[:, cols_with_negones].map(replace_na, replacer=-1)\n",
    "        all_data.iloc[:, cols_with_zeros] = all_data.iloc[:, cols_with_zeros].map(replace_na, replacer=0)\n",
    "\n",
    "        # update all_participants\n",
    "        all_participants = pd.merge(all_participants, condensed, how='right')\n",
    "        \n",
    "        \n",
    "        # pull out the right program\n",
    "        if program == 'Doctoral':\n",
    "            full_data = copy(all_data[np.logical_and((all_data['campus']=='Charles River Campus').to_numpy(), all_data['degree'].str.contains('Doctoral').to_numpy())])\n",
    "            participants = copy(all_participants[np.logical_and((all_participants['campus']=='Charles River Campus').to_numpy(), all_participants['degree'].str.contains('Doctoral').to_numpy())])\n",
    "        elif program == 'Masters':\n",
    "            full_data = copy(all_data[np.logical_and((all_data['campus']=='Charles River Campus').to_numpy(), all_data['degree'].str.contains('Masters').to_numpy())])\n",
    "            participants = copy(all_participants[np.logical_and((all_participants['campus']=='Charles River Campus').to_numpy(), all_participants['degree'].str.contains('Masters').to_numpy())])\n",
    "        elif program == 'Med':\n",
    "            full_data = copy(all_data[(all_data['campus']=='BU Medical Campus').tolist()])\n",
    "            participants = copy(participants[(participants['campus']=='BU Medical Campus').tolist()])\n",
    "        elif program == 'Virtual':\n",
    "            full_data = copy(all_data[(all_data['campus']=='Virtual').tolist()])\n",
    "            participants = copy(participants[(participants['campus']=='Virtual').tolist()])\n",
    "        data = copy(full_data[(participants['optin'+str(round_widget.value)]=='Yes').to_numpy()])\n",
    "        \n",
    "\n",
    "    # calculate the number of groups of 3 and 4 we will have \n",
    "    n = len(data)\n",
    "    if groupsize_widget.value == 3:\n",
    "        # make groups of 3 and fill in the gaps with groups of 4\n",
    "        number3groups = n // 3\n",
    "        number4groups = n - (number3groups * 3)\n",
    "        number3groups = n // 3 - number4groups\n",
    "    elif groupsize_widget.value == 4:\n",
    "        # make groups of 4 and fill in the gaps with groups of 3\n",
    "        nn = n\n",
    "        number3groups = 0\n",
    "        while (nn / 4 - np.floor(nn / 4)) != 0:\n",
    "            nn -= 3 # keep subtracting groups of 3 until it's divisible by 4\n",
    "            number3groups += 1\n",
    "        number4groups = nn // 4\n",
    "\n",
    "\n",
    "        print('Previous round completed')\n",
    "    print('All data structures made')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ed2ba5ef",
   "metadata": {},
   "source": [
    "complete_match(all_data)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6e2a51a4",
   "metadata": {},
   "source": [
    "all_data_prev = copy(all_data)\n",
    "all_data = pd.merge(condensed.loc[:, condensed.columns[:-1]], all_data, how='left')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "43aa3d11",
   "metadata": {},
   "source": [
    "prior_match_col = np.where(all_data.columns == 'prior_matches')[0][0]\n",
    "current_match_col = np.where(all_data.columns == 'current_match')[0][0]\n",
    "possible_match_col = np.where(all_data.columns == 'possible_matches')[0][0]\n",
    "\n",
    "current_group_col = np.where(all_data.columns == 'current_group')[0][0]\n",
    "num_possible_matches_col = np.where(all_data.columns == 'num_possible_matches')[0][0]\n",
    "\n",
    "num_prior_matches_col = np.where(all_data.columns == 'num_prior_matches')[0][0]\n",
    "size_prev_match_col = np.where(all_data.columns == 'size_prev_match')[0][0]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7f7a4483",
   "metadata": {},
   "source": [
    "all_data_save = copy(all_data)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0d92c26a",
   "metadata": {},
   "source": [
    "def replace_na(value, replacer):\n",
    "    if value == []:\n",
    "        return value\n",
    "    try:\n",
    "        if pd.isna(value):\n",
    "            return replacer\n",
    "        return value\n",
    "    except ValueError as e:\n",
    "        return value"
   ]
  },
  {
   "cell_type": "raw",
   "id": "19ac1096",
   "metadata": {},
   "source": [
    "cols_with_lists = [prior_match_col, current_match_col, possible_match_col]\n",
    "cols_with_negones = [current_group_col, num_possible_matches_col]\n",
    "cols_with_zeros = [num_prior_matches_col, size_prev_match_col]\n",
    "#cols_with_zeros = list(range(2, df.shape[1]))  # Columns 2 and beyond\n",
    "\n",
    "# set up columns as needed\n",
    "all_data.iloc[:, cols_with_lists] = all_data.iloc[:, cols_with_lists].map(replace_na, replacer=[])\n",
    "all_data.iloc[:, cols_with_negones] = all_data.iloc[:, cols_with_negones].map(replace_na, replacer=-1)\n",
    "all_data.iloc[:, cols_with_zeros] = all_data.iloc[:, cols_with_zeros].map(replace_na, replacer=0)\n",
    "\n",
    "# Replace NaNs with 0s in specified columns\n",
    "#df.iloc[:, cols_with_zeros] = df.iloc[:, cols_with_zeros].fillna(0)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6906fc55",
   "metadata": {},
   "source": [
    "all_participants = pd.merge(all_participants, condensed, how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4007930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa988d48",
   "metadata": {},
   "source": [
    "THINGS IN PROGRESS:\n",
    "\n",
    "Need to create all_participants for rounds 2+\n",
    "\n",
    "Everything is still using indices when it should be using be using the User_IDs"
   ]
  },
  {
   "cell_type": "raw",
   "id": "12b9921d",
   "metadata": {},
   "source": [
    "# explore how this might be done better\n",
    "pd.merge(all_participants, all_data_prev, left_index=True, right_index=True, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "39ed6206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d74028e4252484a8b7ca9ab6b2dc51f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Matching round:', index=1, options=(1, 2, 3, 4, 5, 6, 7, 8, 9), style=DescriptionStyle(d"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9a939c1e0834e15be9ef2c38cfbd183",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Spreadsheet name:', style=TextStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66630709921f419893a64bbd465ff66a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Group Size', options=(4, 3), style=DescriptionStyle(description_width='initial'), value="
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b17812860cca428aa30c0eb88304651b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Email password:', style=TextStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5a9229fe2f14464b6a754d73a6ed78b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='Allow 2 law students in a group if necessary', style=CheckboxStyle(descript"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20944c2ff873423388c3391b402f0723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Run Match, Notify Groups, Update Data', layout=Layout(height='35px', width='auto'), style="
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e57d0edac6b470fbdab5a19bb701161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Remind Groups', layout=Layout(height='35px', width='auto'), style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clear_output()\n",
    "display_widget()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37254df8",
   "metadata": {},
   "source": [
    "Don't forget to move the opt-in number checker to the new opt-in merging location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "30ed4e08",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous round completed\n",
      "All data structures made\n"
     ]
    }
   ],
   "source": [
    "create_data(program='Doctoral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "132d1138",
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_matches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "ab353dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \r",
      "match created\n"
     ]
    }
   ],
   "source": [
    "create_match()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "2dbaa7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = copy(full_data)\n",
    "aa = copy(participants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "213506d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous round completed\n",
      "All data structures made\n"
     ]
    }
   ],
   "source": [
    "create_data(program='Masters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "122e133a",
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_matches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "279cac0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \r",
      "match created\n"
     ]
    }
   ],
   "source": [
    "create_match()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "5572e459",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = copy(full_data)\n",
    "bb = copy(participants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "74754242",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Item wrong length 0 instead of 287.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_z/5382fyf919n7cf9211lb816c0000gn/T/ipykernel_87630/2903513855.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcreate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprogram\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Med'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/_z/5382fyf919n7cf9211lb816c0000gn/T/ipykernel_87630/104157148.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(program)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mparticipants\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparticipants\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparticipants\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'campus'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'BU Medical Campus'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mprogram\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Virtual'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mfull_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'campus'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'Virtual'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mparticipants\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparticipants\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparticipants\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'campus'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'Virtual'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparticipants\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optin'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround_widget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'Yes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;31m# calculate the number of groups of 3 and 4 we will have\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py312/lib/python3.12/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4089\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4091\u001b[0m         \u001b[0;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4092\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4093\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_bool_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4095\u001b[0m         \u001b[0;31m# We are left with two options: a single key, and a collection of keys,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4096\u001b[0m         \u001b[0;31m# We interpret tuples as collections only for non-MultiIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py312/lib/python3.12/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4139\u001b[0m                 \u001b[0mUserWarning\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4140\u001b[0m                 \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4141\u001b[0m             \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4142\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4143\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   4144\u001b[0m                 \u001b[0;34mf\"\u001b[0m\u001b[0;34mItem wrong length \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m instead of \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4145\u001b[0m             \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Item wrong length 0 instead of 287."
     ]
    }
   ],
   "source": [
    "create_data(program='Med')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "11cdffa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_matches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f1354ede",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \r",
      "match created\n"
     ]
    }
   ],
   "source": [
    "create_match()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "62bfeef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = copy(full_data)\n",
    "cc = copy(participants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c9065e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous round completed\n",
      "All data structures made\n"
     ]
    }
   ],
   "source": [
    "create_data(program='Virtual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cb788265",
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_matches(samedepartment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cc375268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \r",
      "match created\n"
     ]
    }
   ],
   "source": [
    "create_match()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "40f125d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = copy(full_data)\n",
    "dd = copy(participants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "06440e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([a, b, c, d]).sort_values('User_ID')\n",
    "all_participants = pd.concat([aa, bb, cc, dd]).sort_values('User_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cb66ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2722d9b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e853ca32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data():\n",
    "    if out == 0:\n",
    "        print('match failed, no data saved')\n",
    "    else:\n",
    "        global all_data_to_save, all_participants_to_save\n",
    "        # create data in a format that can be saved to Google\n",
    "        # add headers and index to the data\n",
    "\n",
    "        intake_to_save = copy(intake.astype('str').values.tolist())\n",
    "        intake_index = intake.index.tolist()\n",
    "        #for i, idx_value in enumerate(intake_index):\n",
    "        #    intake_to_save[i].insert(0, idx_value)\n",
    "        intake_to_save.insert(0, intake.columns.values.tolist())\n",
    "        \n",
    "        condensed_to_save = copy(condensed.loc[:, :condensed.columns[-2]].astype('str').values.tolist())\n",
    "        condensed_index = condensed.index.tolist()\n",
    "        #for i, idx_value in enumerate(condensed_index):\n",
    "        #    condensed_to_save[i].insert(0, idx_value)\n",
    "        condensed_to_save.insert(0, condensed.loc[:, :condensed.columns[-2]].columns.values.tolist())\n",
    "        \n",
    "        all_data_to_save = copy(all_data.astype('str').values.tolist())\n",
    "        all_data_index = all_data.index.tolist()\n",
    "        #for i, idx_value in enumerate(all_data_index):\n",
    "        #    all_data_to_save[i].insert(0, idx_value)\n",
    "        all_data_to_save.insert(0, all_data.columns.values.tolist())\n",
    "\n",
    "        all_participants_to_save = copy(all_participants.astype('str').values.tolist())\n",
    "        all_participants_index = all_participants.index.tolist()\n",
    "        #for i, idx_value in enumerate(all_participants_index):\n",
    "        #    all_participants_to_save[i].insert(0, idx_value)\n",
    "        all_participants_to_save.insert(0, all_participants.columns.values.tolist())\n",
    "\n",
    "        try:\n",
    "            master.add_worksheet('intake_list', rows=len(intake)+2, cols=len(intake.columns)+2)\n",
    "        except:\n",
    "            pass\n",
    "        master.worksheet('intake_list').clear()\n",
    "        master.worksheet('intake_list').update(range_name='A1', values=intake_to_save)   \n",
    "\n",
    "        \n",
    "        try:\n",
    "            master.add_worksheet('condensed_responses', rows=len(condensed)+2, cols=len(condensed.columns)+2)\n",
    "        except:\n",
    "            pass\n",
    "        master.worksheet('condensed_responses').clear()\n",
    "        master.worksheet('condensed_responses').update(range_name='A1', values=condensed_to_save)   \n",
    "        \n",
    "        try:\n",
    "            master.add_worksheet('all_data', rows=len(all_data)+2, cols=len(all_data.columns)+2)\n",
    "        except:\n",
    "            pass\n",
    "        master.worksheet('all_data').clear()\n",
    "        master.worksheet('all_data').update(range_name='A1', values=all_data_to_save)\n",
    "\n",
    "\n",
    "        try:\n",
    "            master.add_worksheet('all_participants', rows=len(all_participants)+2, cols=len(all_participants.columns)+2)\n",
    "        except:\n",
    "            pass\n",
    "        master.worksheet('all_participants').clear()\n",
    "        master.worksheet('all_participants').update(range_name='A1', values=all_participants_to_save)     \n",
    "\n",
    "        print('spreadsheets updated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8c763360",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_z/5382fyf919n7cf9211lb816c0000gn/T/ipykernel_87630/119294838.py:38: DeprecationWarning: [Deprecated][in version 6.0.0]: Method signature's arguments 'range_name' and 'values' will change their order. We recommend using named arguments for minimal impact. In addition, the argument 'values' will be mandatory of type: 'List[List]'. (ex) Worksheet.update(values = [[]], range_name=) \n",
      "  master.worksheet('intake_list').update(range_name='A1', values=intake_to_save)\n",
      "/var/folders/_z/5382fyf919n7cf9211lb816c0000gn/T/ipykernel_87630/119294838.py:46: DeprecationWarning: [Deprecated][in version 6.0.0]: Method signature's arguments 'range_name' and 'values' will change their order. We recommend using named arguments for minimal impact. In addition, the argument 'values' will be mandatory of type: 'List[List]'. (ex) Worksheet.update(values = [[]], range_name=) \n",
      "  master.worksheet('condensed_responses').update(range_name='A1', values=condensed_to_save)\n",
      "/var/folders/_z/5382fyf919n7cf9211lb816c0000gn/T/ipykernel_87630/119294838.py:53: DeprecationWarning: [Deprecated][in version 6.0.0]: Method signature's arguments 'range_name' and 'values' will change their order. We recommend using named arguments for minimal impact. In addition, the argument 'values' will be mandatory of type: 'List[List]'. (ex) Worksheet.update(values = [[]], range_name=) \n",
      "  master.worksheet('all_data').update(range_name='A1', values=all_data_to_save)\n",
      "/var/folders/_z/5382fyf919n7cf9211lb816c0000gn/T/ipykernel_87630/119294838.py:61: DeprecationWarning: [Deprecated][in version 6.0.0]: Method signature's arguments 'range_name' and 'values' will change their order. We recommend using named arguments for minimal impact. In addition, the argument 'values' will be mandatory of type: 'List[List]'. (ex) Worksheet.update(values = [[]], range_name=) \n",
      "  master.worksheet('all_participants').update(range_name='A1', values=all_participants_to_save)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spreadsheets updated\n"
     ]
    }
   ],
   "source": [
    "save_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be70570",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf7eee7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
