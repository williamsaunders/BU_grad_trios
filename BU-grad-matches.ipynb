{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fa00c7b",
   "metadata": {},
   "source": [
    "Order of things to do:\n",
    "1. Import \n",
    "    - Round 1: Takes in the master cleaned list and opt-in list\n",
    "    - Rounds 2+: Takes in the master cleaned list, opt-in list, participants list, and full data list. \n",
    "    - Returns master and opt-in or errors (telling you what to fix)\n",
    "2. Dedup\n",
    "    - De-duplicates the opt-in and master lists. \n",
    "3. Sync\n",
    "    - Takes in master and opt-in lists.\n",
    "    - Returns participant list with new rows if necessary.\n",
    "4. Create data\n",
    "    - Produces or updates the full data list. \n",
    "5. Complete match  \n",
    "    - Completes the previous round if round > 1     \n",
    "6. Possible matches  \n",
    "7. Create match   \n",
    "8. Save data back to Google.\n",
    "9. Send emails.\n",
    "10. Send reminder emails.\n",
    "\n",
    "\n",
    "\n",
    "- Make sure that retrieved data doesn't become corrupted. \n",
    "- Make sure that the names of spreadsheets are passed along correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8075b941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "from matplotlib_inline import backend_inline\n",
    "backend_inline.set_matplotlib_formats('retina')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "#from openpyxl import load_workbook\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from ipywidgets import HBox, VBox\n",
    "from IPython.display import HTML\n",
    "import base64\n",
    "\n",
    "import json\n",
    "import os\n",
    "from email.mime.text import MIMEText\n",
    "from email.message import EmailMessage\n",
    "import ssl\n",
    "import smtplib\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "\n",
    "import requests\n",
    "\n",
    "import gspread\n",
    "#gc = gspread.oauth()\n",
    "gc = gspread.oauth(\n",
    "        credentials_filename='credentials-bumeetup.json',\n",
    "        #authorized_user_filename='authorized_user.json',\n",
    "    )\n",
    "\n",
    "def copy(obj):\n",
    "    # true deep copy\n",
    "    return pickle.loads(pickle.dumps(obj))\n",
    "\n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx\n",
    "\n",
    "def convert_cell(cell):\n",
    "    # converts '[1, 2, 3, ...]' into [1, 2, 3, ...]\n",
    "    if cell != '[]':\n",
    "        a = cell.strip('][').split(', ')\n",
    "        b = [int(i) for i in a]\n",
    "        return b\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def init(df):\n",
    "    # reset some of the columns or create them if they don't exist \n",
    "    df['prior_matches'] = [ [] for _ in range(len(df)) ]\n",
    "    df['current_match'] = [ [] for _ in range(len(df)) ]\n",
    "    df['current_group'] = -1\n",
    "    df['num_prior_matches'] = 0\n",
    "    df['size_prev_match'] = 0 # whether were in a 3 or 4 group previously, or 0 if new\n",
    "    df['possible_matches'] = [ [] for _ in range(len(df)) ]\n",
    "    df['num_possible_matches'] = -1\n",
    "\n",
    "def create_download_link(df, title=\"Download CSV file\", filename=\"data.csv\"): \n",
    "    # turns the pandas DataFrame into a csv to download\n",
    "    csv = df.to_csv(index=True)\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n",
    "    html = html.format(payload=payload,title=title,filename=filename)\n",
    "    display(HTML(html))\n",
    "\n",
    "def import_files():\n",
    "    # imports the round opt-ins and the previous round matching data\n",
    "    global master, intake, condensed, all_participants, full_data, data, optin, number3groups, number4groups, participants_prev, \\\n",
    "    participants, full_data_prev, all_data_prev, groupnum\n",
    "    \n",
    "    # import intake sheet from master file\n",
    "    master = gc.open(master_file)\n",
    "    intake = master.worksheet('intake_list')\n",
    "    intake = np.array(intake.get_all_values())\n",
    "    intake = pd.DataFrame(data=intake[1:,:], columns=intake[0,:])\n",
    "    email_cols = [_ for _ in intake.columns if 'email' in _]\n",
    "    intake[email_cols[0]] = intake[email_cols[0]].str.lower()\n",
    "    intake[email_cols[0]] = intake[email_cols[0]].str.strip()\n",
    "    intake[email_cols[1]] = intake[email_cols[1]].str.lower()\n",
    "    intake[email_cols[1]] = intake[email_cols[1]].str.strip()\n",
    "    # assign new unique ids to new participants\n",
    "    need_new_unique_ids = np.arange(intake[intake['User ID'] != ''].index[-1]+1, len(intake))\n",
    "    intake['User ID'] = intake.loc[intake['User ID'] != '', 'User ID'].astype(int).tolist() + [int(intake.loc[need_new_unique_ids[0]-1, 'User ID'])+i+1 for i, index in enumerate(need_new_unique_ids)]\n",
    "\n",
    "    # dedup the intake list by keeping only the first\n",
    "    intake.drop_duplicates(subset=['What is your BU email address?'], keep='first', inplace=True)\n",
    "\n",
    "    # create or update the condensed_responses sheet\n",
    "    condensed = copy(intake.iloc[:, np.arange(0, 10)])\n",
    "    condensed.columns = ['User_ID', 'Timestamp', 'full_name', 'first_name', 'pronouns', 'email', 'email_retype', 'campus', 'degree', 'school']\n",
    "    condensed_department_columns = intake.iloc[:, np.arange(10, len(intake.columns))]\n",
    "    condensed_department_column = []\n",
    "    for index, row in condensed_department_columns.iterrows():\n",
    "        for i, item in enumerate(row):\n",
    "            if item != '':\n",
    "                condensed_department_column.append(item)\n",
    "                break\n",
    "            if i+1 == len(row):\n",
    "                condensed_department_column.append(condensed.loc[index, 'school'])\n",
    "    condensed['department'] = condensed_department_column\n",
    "\n",
    "    # import opt-in sheet\n",
    "    optin_sheet = master.worksheet('optin' + str(round_widget.value))\n",
    "    optin = np.array(optin_sheet.get_all_values())\n",
    "    optin = pd.DataFrame(data=optin[1:,:], columns=['email', 'available'])\n",
    "    optin = copy(optin[optin['available'] == 'Yes'])\n",
    "    optin['email'] = optin['email'].str.lower()\n",
    "    optin['email'] = optin['email'].str.strip()\n",
    "\n",
    "    # remove duplicates in the optin\n",
    "    optin = optin.drop_duplicates(subset='email', keep='last') # keep the last in case someone changed \n",
    "\n",
    "    # merge the optin into condensed \n",
    "    condensed = pd.merge(condensed, optin[['email', 'available']], on='email', how='left')\n",
    "    condensed['available'] = condensed['available'].fillna('No')\n",
    "    condensed.rename(columns={'available': 'optin' + str(round_widget.value)}, inplace=True)\n",
    "    \n",
    "    if round_widget.value > 1:\n",
    "        all_data_prev_sheet = master.worksheet('all_data')\n",
    "        all_data_prev = np.array(all_data_prev_sheet.get_all_values())\n",
    "        all_data_prev = pd.DataFrame(data=all_data_prev[1:,:], columns=all_data_prev[0,:])\n",
    "        \n",
    "        all_participants_prev_sheet = master.worksheet('all_participants')\n",
    "        all_participants_prev = np.array(all_participants_prev_sheet.get_all_values())\n",
    "        all_participants_prev = pd.DataFrame(data=all_participants_prev[1:,:], columns=all_participants_prev[0,:])\n",
    "        all_participants_prev['User_ID'] = [int(row['User_ID']) for index, row in all_participants_prev.iterrows()]\n",
    "        \n",
    "        all_participants_prev_mini = pd.concat([all_participants_prev[['User_ID']], all_participants_prev.iloc[:, 11:]], axis=1)\n",
    "        all_participants = pd.merge(condensed, all_participants_prev_mini, on=['User_ID'], how='left')\n",
    "        all_participants.insert(len(all_participants.columns)-1, 'optin' + str(round_widget.value), all_participants.pop('optin' + str(round_widget.value)))\n",
    "    \n",
    "    groupnum = 1 # reset the group number for the new group matching\n",
    "    \n",
    "def complete_match(df):\n",
    "    # move the current match to the end of the list of prior matches and clear the columns \n",
    "    for index, row in df.iterrows():\n",
    "        df.loc[index, 'prior_matches'].extend(row['current_match'])\n",
    "        df.loc[index, 'num_prior_matches'] = len(row['prior_matches'])\n",
    "    df['size_prev_match'] = [len(a) for a in df['current_match'].tolist()]\n",
    "    df['current_match'] = [ [] for _ in range(len(df)) ]\n",
    "    df['current_group'] = -1\n",
    "\n",
    "def create_data(program):\n",
    "    # program must be one of the following: 'Doctoral', 'Masters', 'Med', 'Virtual'\n",
    "    global all_data, all_participants, all_data_prev, all_participants_prev, full_data, data, number3groups, number4groups, \\\n",
    "    participants_round, participants, groupnum\n",
    "    \n",
    "    if round_widget.value == 1:\n",
    "        # create the full_data list from scratch\n",
    "        if program == 'Doctoral':\n",
    "            participants = copy(condensed[np.logical_and((condensed['campus']=='Charles River Campus').to_numpy(), condensed['degree'].str.contains('Doctoral').to_numpy())])\n",
    "            full_data = copy(participants)\n",
    "        elif program == 'Masters':\n",
    "            participants = copy(condensed[np.logical_and((condensed['campus']=='Charles River Campus').tolist(), condensed['degree'].str.contains('Masters').tolist())])\n",
    "            full_data = copy(participants)\n",
    "        elif program == 'Med':\n",
    "            participants = copy(condensed[(condensed['campus']=='BU Medical Campus').tolist()])\n",
    "            full_data = copy(participants)\n",
    "        elif program == 'Virtual':\n",
    "            participants = copy(condensed[(condensed['campus']=='Virtual').tolist()])\n",
    "            full_data = copy(participants)\n",
    "        full_data.drop(columns='optin1', inplace=True)\n",
    "        data = copy(full_data[(participants['optin'+str(round_widget.value)]=='Yes').to_numpy()])\n",
    "        init(full_data)\n",
    "        init(data)\n",
    "\n",
    "    if round_widget.value > 1:\n",
    "        '''\n",
    "        # format the entries correctly\n",
    "        all_data_prev['prior_matches'] = \\\n",
    "            [convert_cell(row['prior_matches']) for index, row in all_data_prev.iterrows()]\n",
    "        all_data_prev['current_match'] = \\\n",
    "            [convert_cell(row['current_match']) for index, row in all_data_prev.iterrows()]\n",
    "        all_data_prev['possible_matches'] = \\\n",
    "            [convert_cell(row['possible_matches']) for index, row in all_data_prev.iterrows()]\n",
    "        all_data_prev['email'] = all_data_prev['email'].str.lower()\n",
    "        all_data_prev['email'] = all_data_prev['email'].str.strip()\n",
    "        '''\n",
    "\n",
    "        # initialize empty rows in the data file for new participants\n",
    "        # this take a lot of lines\n",
    "        a = pd.merge(all_participants, all_data_prev, left_index=True, right_index=True, how='outer')\n",
    "        leftcols = [col for col in a.columns if '_x' in col] # lefthand side columns to keep \n",
    "        rightcols = a.columns[-7:] # righthand side columns to keep\n",
    "        a = a[np.append(leftcols, rightcols)]\n",
    "        a.columns = all_data_prev.columns\n",
    "        a['prior_matches'] = a['prior_matches'].apply(lambda d: d if isinstance(d, list) else [])\n",
    "        a['current_match'] = a['current_match'].apply(lambda d: d if isinstance(d, list) else [])\n",
    "        a['current_group'] = a['current_group'].fillna(-1)\n",
    "        a['num_prior_matches'] = a['num_prior_matches'].fillna(0)\n",
    "        a['size_prev_match'] = a['size_prev_match'].fillna(0)\n",
    "        a['possible_matches'] = a['possible_matches'].apply(lambda d: d if isinstance(d, list) else [])\n",
    "        a['num_possible_matches'] = a['num_possible_matches'].fillna(-1)\n",
    "        all_data = copy(a)\n",
    "\n",
    "        # create data array for just the opt-ins\n",
    "        #if len(all_data) != len(participants):\n",
    "        #    print('ERROR: length of `all_data` doesn\\'t equal length of `participants`.')\n",
    "        #data = copy(all_data[participants['optin'+str(round_widget.value)]=='Yes'])\n",
    "        \n",
    "        complete_match(all_data)\n",
    "        print('Previous round completed')\n",
    "        # _prev is from the end of the previous match (without new signups added)\n",
    "        all_data_prev = copy(all_data)\n",
    "        # add in the new signups that we already have in the condensed list\n",
    "        all_data = pd.merge(condensed.loc[:, condensed.columns[:-1]], all_data, how='left')\n",
    "        \n",
    "        # prep the new columns as needed\n",
    "        prior_match_col = np.where(all_data.columns == 'prior_matches')[0][0]\n",
    "        current_match_col = np.where(all_data.columns == 'current_match')[0][0]\n",
    "        possible_match_col = np.where(all_data.columns == 'possible_matches')[0][0]\n",
    "        current_group_col = np.where(all_data.columns == 'current_group')[0][0]\n",
    "        num_possible_matches_col = np.where(all_data.columns == 'num_possible_matches')[0][0]\n",
    "        num_prior_matches_col = np.where(all_data.columns == 'num_prior_matches')[0][0]\n",
    "        size_prev_match_col = np.where(all_data.columns == 'size_prev_match')[0][0]\n",
    "        \n",
    "        def replace_na(value, replacer):\n",
    "            if value == []:\n",
    "                return value\n",
    "            try:\n",
    "                if pd.isna(value):\n",
    "                    return replacer\n",
    "                return value\n",
    "            except ValueError as e:\n",
    "                return value\n",
    "    \n",
    "        cols_with_lists = [prior_match_col, current_match_col, possible_match_col]\n",
    "        cols_with_negones = [current_group_col, num_possible_matches_col]\n",
    "        cols_with_zeros = [num_prior_matches_col, size_prev_match_col]\n",
    "        all_data.iloc[:, cols_with_lists] = all_data.iloc[:, cols_with_lists].map(replace_na, replacer=[])\n",
    "        all_data.iloc[:, cols_with_negones] = all_data.iloc[:, cols_with_negones].map(replace_na, replacer=-1)\n",
    "        all_data.iloc[:, cols_with_zeros] = all_data.iloc[:, cols_with_zeros].map(replace_na, replacer=0)\n",
    "\n",
    "        # update all_participants\n",
    "        all_participants = pd.merge(all_participants, condensed, how='right')\n",
    "        \n",
    "        \n",
    "        # pull out the right program\n",
    "        if program == 'Doctoral':\n",
    "            full_data = copy(all_data[np.logical_and((all_data['campus']=='Charles River Campus').to_numpy(), all_data['degree'].str.contains('Doctoral').to_numpy())])\n",
    "            participants = copy(all_participants[np.logical_and((all_participants['campus']=='Charles River Campus').to_numpy(), all_participants['degree'].str.contains('Doctoral').to_numpy())])\n",
    "        elif program == 'Masters':\n",
    "            full_data = copy(all_data[np.logical_and((all_data['campus']=='Charles River Campus').to_numpy(), all_data['degree'].str.contains('Masters').to_numpy())])\n",
    "            participants = copy(all_participants[np.logical_and((all_participants['campus']=='Charles River Campus').to_numpy(), all_participants['degree'].str.contains('Masters').to_numpy())])\n",
    "        elif program == 'Med':\n",
    "            full_data = copy(all_data[(all_data['campus']=='BU Medical Campus').tolist()])\n",
    "            participants = copy(all_participants[(all_participants['campus']=='BU Medical Campus').tolist()])\n",
    "        elif program == 'Virtual':\n",
    "            full_data = copy(all_data[(all_data['campus']=='Virtual').tolist()])\n",
    "            participants = copy(all_participants[(all_participants['campus']=='Virtual').tolist()])\n",
    "        data = copy(full_data[(participants['optin'+str(round_widget.value)]=='Yes').to_numpy()])\n",
    "        \n",
    "\n",
    "    # calculate the number of groups of 3 and 4 we will have \n",
    "    n = len(data)\n",
    "    if groupsize_widget.value == 3:\n",
    "        # make groups of 3 and fill in the gaps with groups of 4\n",
    "        number3groups = n // 3\n",
    "        number4groups = n - (number3groups * 3)\n",
    "        number3groups = n // 3 - number4groups\n",
    "    elif groupsize_widget.value == 4:\n",
    "        # make groups of 4 and fill in the gaps with groups of 3\n",
    "        nn = n\n",
    "        number3groups = 0\n",
    "        while (nn / 4 - np.floor(nn / 4)) != 0:\n",
    "            nn -= 3 # keep subtracting groups of 3 until it's divisible by 4\n",
    "            number3groups += 1\n",
    "        number4groups = nn // 4\n",
    "\n",
    "\n",
    "    print('All data structures made')\n",
    "    \n",
    "def possible_matches(samedepartment=False):\n",
    "    # determines all the possible matches for each person in the program\n",
    "    # if samedepartment=False, DON'T allow 2 from same department\n",
    "    # if samedepartment=True, DO allow 2 from same department (for Virtual only right now)\n",
    "    data['possible_matches'] = [ [] for _ in range(len(data)) ]\n",
    "    data['num_possible_matches'] = -1\n",
    "    if samedepartment == False:\n",
    "        for index, row in data.iterrows():\n",
    "            non_previous_matches = data.User_ID.to_numpy()[~np.in1d(data.User_ID.to_numpy(), row['prior_matches'])]\n",
    "            non_same_department = data.User_ID.to_numpy()[~(row['department'] == data['department'])]\n",
    "            data.loc[index, 'possible_matches'].extend(np.intersect1d(non_previous_matches, non_same_department))\n",
    "            data.loc[index, 'num_possible_matches'] = len(data.loc[index, 'possible_matches'])\n",
    "    if samedepartment == True:\n",
    "        for index, row in data.iterrows():\n",
    "            non_previous_matches = data.User_ID.to_numpy()[~np.in1d(data.User_ID.to_numpy(), row['prior_matches'])]\n",
    "            data.loc[index, 'possible_matches'].extend(non_previous_matches)\n",
    "            data.loc[index, 'num_possible_matches'] = len(data.loc[index, 'possible_matches'])    \n",
    "\n",
    "def perform_random_loop(df):\n",
    "    global groupnum\n",
    "    # the loop that attempts to do the matching\n",
    "    out = 0 # variable to determine when we've succeeded\n",
    "    # clear any attemps to match that failed\n",
    "    df['current_match'] = [ [] for _ in range(len(df)) ]\n",
    "    df['current_group'] = -1\n",
    "    # create a random column \n",
    "    df.loc[:, 'randint'] = np.random.choice(np.arange(0, len(df)), size=len(df), replace=False)\n",
    "    \n",
    "    # iterate through, starting with the most number of possible matches \n",
    "    for i, (index, row) in enumerate(df.sort_values(['size_prev_match', \\\n",
    "                                                     'num_possible_matches', \\\n",
    "                                                     'randint']).iterrows()):\n",
    "        # select possible matches for person1\n",
    "        if i == 0:\n",
    "            p1_possible = df.loc[index, 'possible_matches']\n",
    "        elif i > 0 :\n",
    "            if len(remaining) == 0:\n",
    "                out = 1\n",
    "                return out\n",
    "                break\n",
    "            elif index not in remaining.index.tolist(): \n",
    "                continue\n",
    "            else:\n",
    "                p1_possible = np.intersect1d(remaining.loc[index, 'possible_matches'], \\\n",
    "                                             remaining.User_ID.tolist())\n",
    "        if len(p1_possible) <= 1:\n",
    "            return out\n",
    "            break\n",
    "        # pick a random person2\n",
    "        p2 = df[np.in1d(df['User_ID'], p1_possible)].sample(1)\n",
    "        p2_possible = p2['possible_matches'].tolist()\n",
    "        # take person1 possible matches and remove person2 and all of person2's not possible matches\n",
    "        p1p2_possible_step1 = np.array(p1_possible)[~np.isin(p1_possible, p2.User_ID.tolist())] # remove p2\n",
    "        p1p2_possible = p1p2_possible_step1[np.isin(p1p2_possible_step1, p2_possible)]\n",
    "\n",
    "        if len(p1p2_possible) == 0:\n",
    "            return out\n",
    "            break\n",
    "        # pick a random person3\n",
    "        p3 = df[np.in1d(df['User_ID'], p1p2_possible)].sample(1)\n",
    "        p3_possible = p3['possible_matches'].tolist()\n",
    "\n",
    "        if groupnum <= number4groups:\n",
    "            # take person3 out oc p1p2_possible\n",
    "            p1p2p3_possible_step1 = np.array(p1p2_possible)[~np.isin(p1p2_possible, p3.User_ID.tolist())] \n",
    "            # keep only person3's possible matches \n",
    "            p1p2p3_possible = p1p2p3_possible_step1[np.isin(p1p2p3_possible_step1, p3_possible)]\n",
    "            \n",
    "            if len(p1p2p3_possible) == 0:\n",
    "                return out\n",
    "                break\n",
    "            # pick a random person4\n",
    "            p4 = df[np.in1d(df['User_ID'], p1p2p3_possible)].sample(1)\n",
    "\n",
    "            # write the current match for all *4* group members\n",
    "            df.loc[index, 'current_match'].extend([row.User_ID, p2.User_ID.values[0], p3.User_ID.values[0], p4.User_ID.values[0]])\n",
    "            df.loc[p2.index[0], 'current_match'].extend([p2.User_ID.values[0], row.User_ID, p3.User_ID.values[0], p4.User_ID.values[0]])\n",
    "            df.loc[p3.index[0], 'current_match'].extend([p3.User_ID.values[0], row.User_ID, p2.User_ID.values[0], p4.User_ID.values[0]])\n",
    "            df.loc[p4.index[0], 'current_match'].extend([p4.User_ID.values[0], row.User_ID, p2.User_ID.values[0], p3.User_ID.values[0]])\n",
    "            \n",
    "            df.loc[index, 'current_group'] = groupnum\n",
    "            df.loc[p2.index[0], 'current_group'] = groupnum\n",
    "            df.loc[p3.index[0], 'current_group'] = groupnum\n",
    "            df.loc[p4.index[0], 'current_group'] = groupnum\n",
    "            \n",
    "        else:\n",
    "            # write the current match for all *3* group members\n",
    "            df.loc[index, 'current_match'].extend([row.User_ID, p2.User_ID.values[0], p3.User_ID.values[0]])\n",
    "            df.loc[p2.index[0], 'current_match'].extend([p2.User_ID.values[0], row.User_ID, p3.User_ID.values[0]])\n",
    "            df.loc[p3.index[0], 'current_match'].extend([p3.User_ID.values[0], row.User_ID, p2.User_ID.values[0]])\n",
    "            \n",
    "            df.loc[index, 'current_group'] = groupnum\n",
    "            df.loc[p2.index[0], 'current_group'] = groupnum\n",
    "            df.loc[p3.index[0], 'current_group'] = groupnum\n",
    "\n",
    "        # create a new version of the overall df with the matches rows removed\n",
    "        if i == 0:\n",
    "            if groupnum <= number4groups:\n",
    "                remaining = df.loc[df.index.difference((index, p2.index[0], p3.index[0], p4.index[0]))]\n",
    "            else:\n",
    "                remaining = df.loc[df.index.difference((index, p2.index[0], p3.index[0]))]\n",
    "        if i > 0:\n",
    "            if groupnum <= number4groups:\n",
    "                remaining = remaining.loc[remaining.index.difference((index, p2.index[0], \\\n",
    "                                                                      p3.index[0], p4.index[0]))]\n",
    "            else:\n",
    "                remaining = remaining.loc[remaining.index.difference((index, p2.index[0], p3.index[0]))]\n",
    "\n",
    "        if i == len(df) - 1:\n",
    "            out = 1\n",
    "            return out\n",
    "\n",
    "        groupnum+=1\n",
    "\n",
    "def create_match():\n",
    "    # calls the matching loop up to 1000 times to create the match \n",
    "    global out, full_data, data, participants, participants_round, groupnum\n",
    "    groupnum_save = copy(groupnum)\n",
    "    counter = 0\n",
    "    out = 0\n",
    "    while out == 0:\n",
    "        counter += 1\n",
    "        groupnum = copy(groupnum_save)\n",
    "        out = perform_random_loop(data)  \n",
    "        print(counter, '\\r', end='')\n",
    "        if counter >= 1000:\n",
    "            print('match failed, not possible')\n",
    "            break\n",
    "    if out == 1:\n",
    "        print('match created')\n",
    "    if ((out == 0) and (checkbox_widget.value)):\n",
    "        print('Allowing up to 2 law students in the same group...')\n",
    "        # divide the law students into 2 random groups\n",
    "        half_law = len(data[data['department'] == 'School of Law'])//2\n",
    "        data.loc[data[data['department'] == 'School of Law'].sample(half_law).index, 'department'] = 'School of Law 1'\n",
    "        data.loc[data[data['department'] == 'School of Law'].index, 'department'] = 'School of Law 2'\n",
    "        # have to re-run the possible matches determination\n",
    "        possible_matches()\n",
    "        # then continue as normal\n",
    "        counter = 0\n",
    "        while out == 0:\n",
    "            counter += 1\n",
    "            groupnum = copy(groupnum_save)\n",
    "            out = perform_random_loop(data)\n",
    "            print(counter, '\\r', end='')\n",
    "            if counter >= 1000:\n",
    "                print('match failed again, really not possible')\n",
    "                break\n",
    "        if out == 1:\n",
    "            print('match created with double law students')\n",
    "            #print(len(data[(data['current_group'].to_numpy() == -1) & (data['school'].to_numpy() == 'School of Law')]))\n",
    "            counter += 1\n",
    "            \n",
    "    # use data to populate participants_round, full_data, and participants\n",
    "    participants_round = copy(participants[participants['optin' + str(round_widget.value)]=='Yes'])\n",
    "    participants_round['group' + str(round_widget.value)] = data['current_group']\n",
    "    participants_round['group' + str(round_widget.value)] = participants_round['group' + str(round_widget.value)].astype(object)\n",
    "    participants.loc[participants_round.index, 'group' + str(round_widget.value)] = participants_round['group' + str(round_widget.value)]\n",
    "    full_data.loc[data.index, :] = copy(data) \n",
    "    \n",
    "def save_data():\n",
    "    if out == 0:\n",
    "        print('match failed, no data saved')\n",
    "    else:\n",
    "        global all_data_to_save, all_participants_to_save\n",
    "        # create data in a format that can be saved to Google\n",
    "        # add headers and index to the data\n",
    "\n",
    "        intake_to_save = copy(intake.astype('str').values.tolist())\n",
    "        intake_index = intake.index.tolist()\n",
    "        #for i, idx_value in enumerate(intake_index):\n",
    "        #    intake_to_save[i].insert(0, idx_value)\n",
    "        intake_to_save.insert(0, intake.columns.values.tolist())\n",
    "        \n",
    "        condensed_to_save = copy(condensed.loc[:, :condensed.columns[-2]].astype('str').values.tolist())\n",
    "        condensed_index = condensed.index.tolist()\n",
    "        #for i, idx_value in enumerate(condensed_index):\n",
    "        #    condensed_to_save[i].insert(0, idx_value)\n",
    "        condensed_to_save.insert(0, condensed.loc[:, :condensed.columns[-2]].columns.values.tolist())\n",
    "        \n",
    "        all_data_to_save = copy(all_data.astype('str').values.tolist())\n",
    "        all_data_index = all_data.index.tolist()\n",
    "        #for i, idx_value in enumerate(all_data_index):\n",
    "        #    all_data_to_save[i].insert(0, idx_value)\n",
    "        all_data_to_save.insert(0, all_data.columns.values.tolist())\n",
    "\n",
    "        all_participants_to_save = copy(all_participants.astype('str').values.tolist())\n",
    "        all_participants_index = all_participants.index.tolist()\n",
    "        #for i, idx_value in enumerate(all_participants_index):\n",
    "        #    all_participants_to_save[i].insert(0, idx_value)\n",
    "        all_participants_to_save.insert(0, all_participants.columns.values.tolist())\n",
    "\n",
    "        try:\n",
    "            master.add_worksheet('intake_list', rows=len(intake)+2, cols=len(intake.columns)+2)\n",
    "        except:\n",
    "            pass\n",
    "        master.worksheet('intake_list').clear()\n",
    "        master.worksheet('intake_list').update(range_name='A1', values=intake_to_save)   \n",
    "\n",
    "        \n",
    "        try:\n",
    "            master.add_worksheet('condensed_responses', rows=len(condensed)+2, cols=len(condensed.columns)+2)\n",
    "        except:\n",
    "            pass\n",
    "        master.worksheet('condensed_responses').clear()\n",
    "        master.worksheet('condensed_responses').update(range_name='A1', values=condensed_to_save)   \n",
    "        \n",
    "        try:\n",
    "            master.add_worksheet('all_data', rows=len(all_data)+2, cols=len(all_data.columns)+2)\n",
    "        except:\n",
    "            pass\n",
    "        master.worksheet('all_data').clear()\n",
    "        master.worksheet('all_data').update(range_name='A1', values=all_data_to_save)\n",
    "\n",
    "\n",
    "        try:\n",
    "            master.add_worksheet('all_participants', rows=len(all_participants)+2, cols=len(all_participants.columns)+2)\n",
    "        except:\n",
    "            pass\n",
    "        master.worksheet('all_participants').clear()\n",
    "        master.worksheet('all_participants').update(range_name='A1', values=all_participants_to_save)     \n",
    "\n",
    "        print('spreadsheets updated')\n",
    "        \n",
    "def send_emails():\n",
    "    global msg, body, greeting, subject\n",
    "    if out == 0:\n",
    "        print('match failed, no emails sent')\n",
    "    else:\n",
    "        # set up to authenticate \n",
    "        SCOPES = ['https://mail.google.com/']\n",
    "        TOKEN_FILE = 'token.json'\n",
    "        CREDENTIALS_FILE = 'credentials-wsaund.json'\n",
    "        def get_oauth2_credentials():\n",
    "            creds = None\n",
    "            # Load existing token from file if it exists\n",
    "            if os.path.exists(TOKEN_FILE):\n",
    "                creds = Credentials.from_authorized_user_file(TOKEN_FILE, SCOPES)\n",
    "            # If there are no valid credentials, go through the OAuth flow\n",
    "            if not creds or not creds.valid:\n",
    "                if creds and creds.expired and creds.refresh_token:\n",
    "                    creds.refresh(Request())\n",
    "                else:\n",
    "                    flow = InstalledAppFlow.from_client_secrets_file(CREDENTIALS_FILE, SCOPES)\n",
    "                    creds = flow.run_local_server(port=0)\n",
    "                # Save the credentials for future use\n",
    "                with open(TOKEN_FILE, 'w') as token:\n",
    "                    token.write(creds.to_json())\n",
    "            return creds\n",
    "        # perform authentication \n",
    "        creds = get_oauth2_credentials()\n",
    "        email_sender = 'wsaund@bu.edu'\n",
    "        auth_string = base64.b64encode(f'user={email_sender}\\1auth=Bearer {creds.token}\\1\\1'.encode()).decode()\n",
    "        \n",
    "        # write and send the emails\n",
    "        print('sending emails...')\n",
    "        for group_num in np.arange(1, all_matched['current_group'].max()+1):\n",
    "            print(group_num, '\\r', end='')\n",
    "            time.sleep(2)\n",
    "            group = all_matched.loc[all_matched['current_group'] == group_num]\n",
    "            \n",
    "            # Create the email content\n",
    "            email_sheet = master.worksheet('match_email')\n",
    "            email = ''\n",
    "            for l in email_sheet.get_all_values():\n",
    "                if l[0] == '':\n",
    "                    email += '\\n\\n'\n",
    "                elif 'XXX' in l[0]:\n",
    "                    email += l[0].replace('XXX', '%s')\n",
    "                else:\n",
    "                    email += l[0]\n",
    "            subject = 'BU Meetup Round %s'%str(round_widget.value)\n",
    "            greeting = ', ' . join(group['first_name'].tolist()[:-1] + \\\n",
    "                                   ['and ' + group['first_name'].tolist()[-1]])\n",
    "            body = email%(greeting, round_widget.value)\n",
    "            email_recipients = group['email'].tolist()\n",
    "            \n",
    "            msg = MIMEText(body)\n",
    "            msg['Subject'] = subject\n",
    "            msg['From'] = email_sender\n",
    "            msg['To'] = \", \".join(email_recipients) \n",
    "\n",
    "            # Connect to Gmail SMTP server and send email\n",
    "            with smtplib.SMTP('smtp.gmail.com', 587) as server:\n",
    "                server.ehlo()\n",
    "                server.starttls()\n",
    "                server.ehlo()\n",
    "                server.docmd('AUTH', 'XOAUTH2 ' + auth_string)\n",
    "                server.sendmail(email_sender, email_recipients, msg.as_string())\n",
    "            break ########### -------------------------- REMOVE BEFORE RUNNING FOR REAL ------------------------------------------\n",
    "    \n",
    "    print('emails sent       ', '\\r', end='')\n",
    "\n",
    "def send_reminder_emails():\n",
    "    global spreadsheet, full_data, data, number3groups, number4groups, participants_round, participants\n",
    "    print('sending reminder emails...')\n",
    "    for group_num in np.arange(1, data['current_group'].max()+1):\n",
    "        print(group_num, '\\r', end='')\n",
    "        time.sleep(2)\n",
    "        group = data.loc[data['current_group'] == group_num]\n",
    "\n",
    "        email_sender = 'bumeetup@bu.edu'\n",
    "        email_password = password_widget.value\n",
    "\n",
    "        email_recipients = group['email'].tolist()\n",
    "        greeting = ', ' . join(group['first_name'].tolist()[:-1] + \\\n",
    "                               ['and ' + group['first_name'].tolist()[-1]])\n",
    "        \n",
    "        # import the email from the spreadsheet and fix the formatting\n",
    "        email_sheet = spreadsheet.worksheet('reminder_email')\n",
    "        email = ''\n",
    "        for l in email_sheet.get_all_values():\n",
    "            if l[0] == '':\n",
    "                email += '\\n\\n'\n",
    "            elif 'XXX' in l[0]:\n",
    "                email += l[0].replace('XXX', '%s')\n",
    "            else:\n",
    "                email += l[0]\n",
    "        \n",
    "        subject = 'Reminder: BU Meetup Round %s'%str(round_widget.value)\n",
    "        body = email%(greeting, round_widget.value)\n",
    "        \n",
    "        em = EmailMessage()\n",
    "        em['From'] = email_sender\n",
    "        em['To'] = email_recipients\n",
    "        em['Subject'] = subject\n",
    "        em.set_content(body)\n",
    "\n",
    "        context = ssl.create_default_context()\n",
    "\n",
    "        with smtplib.SMTP_SSL('smtp.gmail.com', 465, context=context) as smtp:\n",
    "            smtp.login(email_sender, email_password)\n",
    "            smtp.sendmail(email_sender, email_recipients, em.as_string())\n",
    "\n",
    "    print('reminder emails sent       ', '\\r', end='')\n",
    "\n",
    "    \n",
    "# initialize jupyter widgets \n",
    "style = {'description_width': 'initial'}\n",
    "layout = widgets.Layout(width='auto', height='35px')\n",
    "\n",
    "spreadsheet_widget = widgets.Text(\n",
    "    description='Spreadsheet name:', \n",
    "    disabled=False, \n",
    "    style=style)\n",
    "\n",
    "round_widget = widgets.Dropdown(\n",
    "    options=np.arange(1, 10),\n",
    "    description='Matching round:', \n",
    "    disabled=False, \n",
    "    style=style)\n",
    "\n",
    "groupsize_widget = widgets.Dropdown(\n",
    "    options=[4,3],\n",
    "    description='Group Size',\n",
    "    disabled=False,\n",
    "    style=style)\n",
    "\n",
    "password_widget = widgets.Text(\n",
    "    description='Email password:', \n",
    "    disabled=False, \n",
    "    style=style)\n",
    "\n",
    "checkbox_widget = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Allow 2 law students in a group if necessary',\n",
    "    disabled=False, \n",
    "    style=style)\n",
    "\n",
    "match_button = widgets.Button(description='Run Match, Notify Groups, Update Data', layout=layout, display='flex', \\\n",
    "                              flex_flow='column', align_items='stretch')\n",
    "remind_button = widgets.Button(description='Remind Groups', layout=layout, display='flex', \\\n",
    "                               flex_flow='column', align_items='stretch')\n",
    "\n",
    "def display_widget():\n",
    "    display(round_widget), \\\n",
    "    display(spreadsheet_widget), \\\n",
    "    display(groupsize_widget),\\\n",
    "    display(password_widget), \\\n",
    "    display(checkbox_widget), \\\n",
    "    display(match_button)\n",
    "    display(remind_button)\n",
    "\n",
    "# functions for each widget button press\n",
    "    \n",
    "def event_match(button):\n",
    "    global all_data, all_participants, all_matched, a, aa, b, bb, c, cc, d, dd\n",
    "#     # do everything\n",
    "#     clear_output()\n",
    "#     display_widget()\n",
    "#     time.sleep(1)\n",
    "#     import_files()\n",
    "#     time.sleep(1)\n",
    "#     dedup()\n",
    "#     time.sleep(1)\n",
    "#     sync_lists()\n",
    "#     time.sleep(1)\n",
    "#     create_data()\n",
    "#     time.sleep(1)\n",
    "#     possible_matches()\n",
    "#     time.sleep(1)\n",
    "#     create_match()\n",
    "#     time.sleep(1)\n",
    "#     save_data()\n",
    "#     time.sleep(1)\n",
    "#     send_emails() \n",
    "    # do everything\n",
    "    clear_output()\n",
    "    display_widget()\n",
    "    import_files()\n",
    "    # doctoral program \n",
    "    create_data(program='Doctoral')\n",
    "    possible_matches()\n",
    "    create_match()\n",
    "    a = copy(full_data)\n",
    "    aa = copy(participants)\n",
    "    # master program \n",
    "    create_data(program='Masters')\n",
    "    possible_matches()\n",
    "    create_match()\n",
    "    b = copy(full_data)\n",
    "    bb = copy(participants)\n",
    "    # MED program \n",
    "    create_data(program='Med')\n",
    "    possible_matches()\n",
    "    create_match()\n",
    "    c = copy(full_data)\n",
    "    cc = copy(participants)\n",
    "    # virtual program \n",
    "    create_data(program='Virtual')\n",
    "    possible_matches(samedepartment=True)\n",
    "    create_match()\n",
    "    d = copy(full_data)\n",
    "    dd = copy(participants)\n",
    "    # all results\n",
    "    all_data = pd.concat([a, b, c, d]).sort_values('User_ID')\n",
    "    all_participants = pd.concat([aa, bb, cc, dd]).sort_values('User_ID')\n",
    "    save_data()\n",
    "    all_matched = all_data[all_data['current_group']>=1]\n",
    "    send_emails()\n",
    "    \n",
    "def event_remind(button):\n",
    "    clear_output()\n",
    "    display_widget()\n",
    "    time.sleep(1)\n",
    "    import_for_reminder()\n",
    "    time.sleep(1)\n",
    "    send_reminder_emails() \n",
    "    \n",
    "    \n",
    "# connecting the jupyter buttons to the actions for each button \n",
    "match_button.on_click(event_match)\n",
    "remind_button.on_click(event_remind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5ae0340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# values for testing\n",
    "master_file = \"Intake_Fall23_noemails\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39ed6206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c697e6ef880497bbf39f29990356ad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Matching round:', options=(1, 2, 3, 4, 5, 6, 7, 8, 9), style=DescriptionStyle(descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e25a79b1116747f9b32311749fc0565e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Spreadsheet name:', style=TextStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5570262a14d34eefae21a4831106c7d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Group Size', options=(4, 3), style=DescriptionStyle(description_width='initial'), value=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "170511edcfce4f1282bd54b8255d099f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Email password:', style=TextStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "108b927c4e3d41cd857a54dd19f8e222",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='Allow 2 law students in a group if necessary', style=CheckboxStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c1f64a618ff4e11898c8c5128597474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Run Match, Notify Groups, Update Data', layout=Layout(height='35px', width='auto'), style=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "885d8f1f16774ed8a064b85e0ffff0da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Remind Groups', layout=Layout(height='35px', width='auto'), style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data structures made\n",
      "1 \r",
      "match created\n",
      "All data structures made\n",
      "1 \r",
      "match created\n",
      "All data structures made\n",
      "1 \r",
      "match created\n",
      "All data structures made\n",
      "1 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_z/5382fyf919n7cf9211lb816c0000gn/T/ipykernel_18865/3410253419.py:480: DeprecationWarning: [Deprecated][in version 6.0.0]: Method signature's arguments 'range_name' and 'values' will change their order. We recommend using named arguments for minimal impact. In addition, the argument 'values' will be mandatory of type: 'List[List]'. (ex) Worksheet.update(values = [[]], range_name=) \n",
      "  master.worksheet('intake_list').update(range_name='A1', values=intake_to_save)\n",
      "/var/folders/_z/5382fyf919n7cf9211lb816c0000gn/T/ipykernel_18865/3410253419.py:488: DeprecationWarning: [Deprecated][in version 6.0.0]: Method signature's arguments 'range_name' and 'values' will change their order. We recommend using named arguments for minimal impact. In addition, the argument 'values' will be mandatory of type: 'List[List]'. (ex) Worksheet.update(values = [[]], range_name=) \n",
      "  master.worksheet('condensed_responses').update(range_name='A1', values=condensed_to_save)\n",
      "/var/folders/_z/5382fyf919n7cf9211lb816c0000gn/T/ipykernel_18865/3410253419.py:495: DeprecationWarning: [Deprecated][in version 6.0.0]: Method signature's arguments 'range_name' and 'values' will change their order. We recommend using named arguments for minimal impact. In addition, the argument 'values' will be mandatory of type: 'List[List]'. (ex) Worksheet.update(values = [[]], range_name=) \n",
      "  master.worksheet('all_data').update(range_name='A1', values=all_data_to_save)\n",
      "/var/folders/_z/5382fyf919n7cf9211lb816c0000gn/T/ipykernel_18865/3410253419.py:503: DeprecationWarning: [Deprecated][in version 6.0.0]: Method signature's arguments 'range_name' and 'values' will change their order. We recommend using named arguments for minimal impact. In addition, the argument 'values' will be mandatory of type: 'List[List]'. (ex) Worksheet.update(values = [[]], range_name=) \n",
      "  master.worksheet('all_participants').update(range_name='A1', values=all_participants_to_save)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spreadsheets updated\n",
      "sending emails...\n",
      "emails sent        \r"
     ]
    }
   ],
   "source": [
    "clear_output()\n",
    "display_widget()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de49d438",
   "metadata": {},
   "source": [
    "I need to make the text outputs easier to follow if there's a problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ceb32e7",
   "metadata": {},
   "source": [
    "Next steps: \n",
    "- Stress test\n",
    "- Integrate GroupMe?\n",
    "- Enable the dual law situation if the first pass fails. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e6b1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GroupMe API endpoint for creating a group\n",
    "CREATE_GROUP_URL = 'https://api.groupme.com/v3/groups'\n",
    "\n",
    "# Your GroupMe access token\n",
    "ACCESS_TOKEN = 'geYTLbuxH8PsWSGs5U1VCOYpiYDADQusOUGav635'\n",
    "\n",
    "# GroupMe API endpoint for adding members to a group\n",
    "ADD_MEMBERS_URL = 'https://api.groupme.com/v3/groups/{group_id}/members/add'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf93aef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_groupme(group_name, members):\n",
    "    global payload, headers, response, group_id\n",
    "    # Create a payload with group name and members\n",
    "    payload = {\"name\": group_name}\n",
    "    response = requests.post(CREATE_GROUP_URL, json=payload, params={'token': ACCESS_TOKEN})\n",
    "    \n",
    "    # Check if request was successful\n",
    "    if response.status_code == 201:\n",
    "        group_id = response.json()['response']['id']\n",
    "        print(f\"Group '{group_name}' created successfully with ID: {group_id}\")\n",
    "        \n",
    "        # add members to the group\n",
    "        payload['id'] = group_id\n",
    "        payload[\"members\"] = []\n",
    "        for i in range(len(members[\"nicknames\"])):\n",
    "            payload[\"members\"].append({\"nickname\" : members[\"nicknames\"][i],\n",
    "                                       \"phone_number\" : members[\"phone_numbers\"][i]\n",
    "                                       'email' : members['email'][i]})\n",
    "        # Send POST request to add members to the group\n",
    "        response = requests.post(ADD_MEMBERS_URL.format(group_id=group_id), json=payload, params={'token': ACCESS_TOKEN})\n",
    "        \n",
    "        # Check if request was successful\n",
    "        if response.status_code == 202:\n",
    "            print(f\"Members added successfully to group with ID: {group_id}\")\n",
    "        else:\n",
    "            print(\"Failed to add members to group. Error:\", response.json()['meta']['errors'])\n",
    "    \n",
    "    else:\n",
    "        print(\"Failed to create group. Error:\", response.json()['meta']['errors'])\n",
    "        return None\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80e3ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_name = 'Test Group 10'\n",
    "members = {'nicknames' : ['Will', 'Test'],\n",
    "           'phone_numbers' : ['+1 9144839676','+1 9142661828'],\n",
    "           'email' : ['william.saunders01@gmail.com', 'william.saunders01@gmail.com']}\n",
    "create_group(group_name, members)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae90f2f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6684ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c478f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_groupme_groups():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c163d8fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f40768",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a85625b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7b4c95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8db55e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "87d56d7e",
   "metadata": {},
   "source": [
    "import_files()\n",
    "\n",
    "create_data(program='Doctoral')\n",
    "\n",
    "possible_matches()\n",
    "\n",
    "create_match()\n",
    "\n",
    "groupnum\n",
    "\n",
    "a = copy(full_data)\n",
    "aa = copy(participants)\n",
    "\n",
    "create_data(program='Masters')\n",
    "\n",
    "possible_matches()\n",
    "\n",
    "create_match()\n",
    "\n",
    "groupnum\n",
    "\n",
    "b = copy(full_data)\n",
    "bb = copy(participants)\n",
    "\n",
    "create_data(program='Med')\n",
    "\n",
    "possible_matches()\n",
    "\n",
    "create_match()\n",
    "\n",
    "groupnum\n",
    "\n",
    "c = copy(full_data)\n",
    "cc = copy(participants)\n",
    "\n",
    "create_data(program='Virtual')\n",
    "\n",
    "possible_matches(samedepartment=True)\n",
    "\n",
    "create_match()\n",
    "\n",
    "groupnum\n",
    "\n",
    "d = copy(full_data)\n",
    "dd = copy(participants)\n",
    "\n",
    "all_data = pd.concat([a, b, c, d]).sort_values('User_ID')\n",
    "all_participants = pd.concat([aa, bb, cc, dd]).sort_values('User_ID')\n",
    "\n",
    "save_data()\n",
    "\n",
    "all_matched = all_data[all_data['current_group']>=1]\n",
    "send_emails()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cc86bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
